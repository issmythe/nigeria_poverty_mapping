{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_jzmd0gZE3V"
      },
      "source": [
        "# Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-utfph7aSQBX",
        "outputId": "191abf46-4fc6-46e8-fc3a-043a2c272acc",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#@title Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mksXU_DWf6A6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLHf6-eoZKj-"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "cellView": "form",
        "id": "m8-WQdxrUivl"
      },
      "outputs": [],
      "source": [
        "#@title Installations\n",
        "!pip install --upgrade descartes geopandas plotly pyshp rasterio rtree scikit-misc shapely &> /dev/null\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jznk83WVSP6c",
        "outputId": "d02665d6-e82f-40ec-f435-aff4b424b416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "#@title Imports TODO\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "ROOT = './'\n",
        "\n",
        "import sys\n",
        "sys.path.append(ROOT + 'src/py/')\n",
        "\n",
        "import math\n",
        "import random\n",
        "import time\n",
        "\n",
        "import geopandas as gpd\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from datetime import datetime\n",
        "from scipy.stats import pearsonr, spearmanr, ttest_1samp, ttest_ind\n",
        "from shapely.geometry import Point, Polygon\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from skmisc import loess\n",
        "\n",
        "import constants as c\n",
        "from constants import PALETTE as pal\n",
        "from bing_tile import bing_tile_to_polygon\n",
        "from cv_utils import get_assignments_df\n",
        "from misc_utils import standardize, tile_weighted_avg\n",
        "from pca_utils import fill_missing, run_pca\n",
        "from plot_utils import get_mapping_df, scatterplot, __plot_loess_helper\n",
        "\n",
        "pd.set_option('display.max_columns', 100)\n",
        "\n",
        "DATA_PATH = ROOT + 'data/'\n",
        "NOT_INC_DATA_PATH = 'poverty_map_paper/data/'\n",
        "GEO_PATH = DATA_PATH + 'geo/'\n",
        "EST_PATH = DATA_PATH + 'generated_estimates/'\n",
        "\n",
        "geodata_path = GEO_PATH + 'updated_wards/NGA_Ward_Map.shp'\n",
        "nlss_data_path = DATA_PATH + 'nigeria_hh_survey.csv'\n",
        "\n",
        "today_str = str(datetime.today().month).zfill(2) + \\\n",
        "            str(datetime.today().year % 1000)\n",
        "FIG_PATH = ROOT + 'output/figures/%s/' % today_str\n",
        "OUT_DIR = ROOT + 'output/figure_data/%s/' % today_str\n",
        "\n",
        "! mkdir -p $FIG_PATH && mkdir -p $OUT_DIR\n",
        "\n",
        "import warnings\n",
        "import matplotlib.cbook\n",
        "warnings.filterwarnings('ignore', category=matplotlib.cbook.mplDeprecation)\n",
        "\n",
        "!mkdir -p $FIG_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "giXAk8hHZMxa"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhxvhNDiZPC0"
      },
      "source": [
        "# Read in and process data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uITNVjrvLlDv"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "cellView": "form",
        "id": "q6WdwsNNXAPK"
      },
      "outputs": [],
      "source": [
        "#@title Read in administrative boundaries\n",
        "country = gpd.read_file(DATA_PATH + 'admin_boundaries/country_boundary.shp')\n",
        "states = gpd.read_file(DATA_PATH + 'admin_boundaries/states.shp')\n",
        "lgas = gpd.read_file(DATA_PATH + 'admin_boundaries/lgas.shp')\n",
        "wards = gpd.read_file(DATA_PATH + 'admin_boundaries/wards.shp')\\\n",
        "           .rename({'ward_origi': 'ward_original_name'}, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "cellView": "form",
        "id": "e97E7ThnSP4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c0acc45-daff-4c5b-d79f-c6220543c8e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/cast.py:118: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
            "  arr = construct_1d_object_array_from_listlike(values)\n",
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
            "  if self.run_code(code, result):\n"
          ]
        }
      ],
      "source": [
        "#@title Read in NLSS\n",
        "\n",
        "def get_survey_geom(df):\n",
        "    return Point(df['hh_gps_longitude'], df['hh_gps_latitude'])\n",
        "\n",
        "nlss_data_path = NOT_INC_DATA_PATH + 'nlss/nigeria_hh_survey.csv'\n",
        "nlss_data = pd.read_csv(nlss_data_path)\\\n",
        "                .dropna(subset=['hh_gps_longitude', 'hh_gps_latitude'])\\\n",
        "                .drop(['state', 'lga'], axis=1)\n",
        "nlss_data['geometry'] = nlss_data.apply(get_survey_geom, axis=1)\n",
        "nlss_data['weight'] = nlss_data['popw'] # Use population weights, not household\n",
        "nlss_data = gpd.GeoDataFrame(nlss_data, crs=c.DEFAULT_CRS)\n",
        "nlss_data = gpd.sjoin(nlss_data, wards[['ward', 'lga', 'state', 'geometry']],\n",
        "                        how='left', op='intersects')\\\n",
        "                 .drop(['index_right'], axis=1)\n",
        "\n",
        "nlss_data['log_con'] = nlss_data['totcons_adj'].apply(lambda x: np.log(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7R2jynxMNjgI"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "cellView": "form",
        "id": "PxdK07siSP0k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "092a9466-baa0-4102-b624-20fc544983ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "#@title Read in satellite poverty estimates\n",
        "didl_orig_state = tile_weighted_avg(states, didl_orig_all, 'state', 'estimated_rwi')\\\n",
        "    .rename({'estimated_rwi': 'didl_orig_rwi', 'weighted_pop': 'pop'}, axis=1)\n",
        "didl_orig_lga = tile_weighted_avg(lgas, didl_orig_all, 'lga', 'estimated_rwi')\\\n",
        "    .rename({'estimated_rwi': 'didl_orig_rwi', 'weighted_pop': 'pop'}, axis=1)\n",
        "didl_orig_ward = tile_weighted_avg(wards, didl_orig_all, 'ward', 'estimated_rwi')\\\n",
        "    .rename({'estimated_rwi': 'didl_orig_rwi', 'weighted_pop': 'pop'}, axis=1)\n",
        "\n",
        "didl_orig_all = pd.read_csv(NOT_INC_DATA_PATH + 'estimates/NG_RWI.csv')\n",
        "pop_data = pd.read_csv(NOT_INC_DATA_PATH + 'ng_pop.csv') ##\n",
        "didl_orig_all['geometry'] = didl_orig_all.apply(lambda x: bing_tile_to_polygon(x), axis=1)\n",
        "didl_orig_all = gpd.GeoDataFrame(didl_orig_all.drop('iso2', axis=1)\\\n",
        "                                              .rename({'rwi': 'estimated_rwi'}, axis=1)\n",
        "                                              .merge(pop_data, on=['x', 'y']),\n",
        "                                 crs=c.DEFAULT_CRS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJg0o6kqSPuu",
        "outputId": "fbd1012f-633a-4d2c-fbde-d133a4cd93d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
            "  if self.run_code(code, result):\n"
          ]
        }
      ],
      "source": [
        "#@title Read in DHS -- change for urban only\n",
        "\n",
        "rwi_var = 'hv271'\n",
        "\n",
        "dhs = pd.read_stata(NOT_INC_DATA_PATH + 'dhs/stata_hh/NGHR7AFL.DTA')\n",
        "locs = gpd.read_file(NOT_INC_DATA_PATH + 'dhs/gps_data/NGGE7AFL.shp')\n",
        "\n",
        "# dhs = dhs[dhs['hv025'] == 'urban']\n",
        "\n",
        "# Use DHS-generated RWI\n",
        "dhs_eval = dhs[['hhid', 'hv001', 'shstate', 'hv005', rwi_var]]\\\n",
        "              .rename({'hv001': 'cluster_id', 'hv005': 'weight', rwi_var: 'dhs_rwi'},\n",
        "                      axis=1)\n",
        "dhs_eval['weight'] /= 1000000\n",
        "\n",
        "rename_states = {'fct abuja': 'federal capital territory',\n",
        "                 'nasarawa': 'nassarawa'}\n",
        "dhs_eval['shstate'] = dhs_eval['shstate'].replace(rename_states)\n",
        "\n",
        "dhs_eval = locs[['DHSCLUST', 'geometry']]\\\n",
        "           .merge(dhs_eval, left_on='DHSCLUST', right_on='cluster_id', how='right')\\\n",
        "           .drop('DHSCLUST', axis=1)\n",
        "dhs_eval = gpd.sjoin(dhs_eval,\n",
        "                     wards.drop_duplicates(subset='ward')[['ward', 'lga', 'state', 'geometry']],\n",
        "                     how='left', op='within')\\\n",
        "              .rename({'state': 'geo_state'}, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cH3KHKqfn-yd"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "cellView": "form",
        "id": "eykUJnkQSPro"
      },
      "outputs": [],
      "source": [
        "#@title Add population to administrative boundary dfs\n",
        "states = states.merge(didl_orig_state[['state', 'pop']], how='left')\n",
        "lgas = lgas.merge(didl_orig_lga[['lga', 'pop']], how='left')\n",
        "wards = wards.merge(didl_orig_ward.drop_duplicates(subset='ward')[['ward', 'pop']], how='left')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z40kJLQsRS4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r-YMnw3LQ87q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "cellView": "form",
        "id": "kIAtIxFESPoe"
      },
      "outputs": [],
      "source": [
        "#@title Generate DHS-like rwi for NLSS data -- change for urban only\n",
        "\n",
        "weights_path = DATA_PATH + 'dhs/rwi_weights/rwi_mapping_combined.csv'\n",
        "rwi_weights = pd.read_csv(weights_path)\n",
        "rwi_weights = rwi_weights[['nlss_name', 'one_weight', 'zero_weight']].dropna()\n",
        "rwi_weights = rwi_weights.groupby('nlss_name').mean().reset_index()\n",
        "\n",
        "factor_cols = ['main_water',\n",
        "              'sanitation_type',\n",
        "              'cookstovetype',\n",
        "              'rooftype',\n",
        "              'wallstype',\n",
        "              'floortype']  \n",
        "cont_cols = ['numasset_radio',\n",
        "             'numasset_tv',\n",
        "             'numasset_computer',\n",
        "             'numasset_fridge',\n",
        "             'numasset_table',\n",
        "             'numasset_chair',\n",
        "             'numasset_bed',\n",
        "             'numasset_sofa',\n",
        "             'numasset_ac',\n",
        "             'numasset_iron',\n",
        "             'numasset_generator',\n",
        "             'numasset_fan',\n",
        "             'has_mobile_phone',\n",
        "             'numasset_bike',\n",
        "             'numasset_motorbike',\n",
        "             'numasset_car',\n",
        "             'electricity']\n",
        "\n",
        "nlss_pca_df = fill_missing(nlss_data.copy(), factor_cols, continuous_cols=None)\n",
        "nlss_pca_df['electricity'] = nlss_pca_df['electricity'].apply(lambda x: 1 if x == 'yes' else 0)\n",
        "nlss_pca_df['has_mobile_phone'] = nlss_pca_df['numasset_smartphone'] + \\\n",
        "                                  nlss_pca_df['numasset_regmobilephone']\n",
        "\n",
        "for col in cont_cols:\n",
        "    nlss_pca_df[col] = nlss_pca_df[col].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "nlss_pca_df[cont_cols] = nlss_pca_df[cont_cols].fillna(nlss_pca_df[cont_cols].median())\n",
        "\n",
        "dummy_colnames = []\n",
        "for col in factor_cols:\n",
        "    dummies = pd.get_dummies(nlss_pca_df[col], prefix=col)\n",
        "    dummy_colnames += list(dummies.columns)\n",
        "    nlss_pca_df = pd.concat([nlss_pca_df, dummies], axis=1)\n",
        "\n",
        "nlss_pca_df['memsleep'] = nlss_pca_df['hhsize'] / nlss_pca_df['numsleepingrooms']\n",
        "nlss_pca_df = nlss_pca_df[['hhid', 'memsleep'] + dummy_colnames + cont_cols]\n",
        "\n",
        "def get_catchall_dict(factor_cols, all_cols):\n",
        "    catchall_dict = {}\n",
        "    for col in factor_cols:\n",
        "        for catchall_col in all_cols:\n",
        "            if catchall_col.startswith(col) and 'other' in catchall_col.lower():\n",
        "                catchall_dict[col] = catchall_col\n",
        "                break\n",
        "    assert len(catchall_dict) == len(factor_cols)\n",
        "    return catchall_dict\n",
        "\n",
        "def get_catchall_column(col_to_match, factor_cols, catchall_dict):\n",
        "    for fc in factor_cols:\n",
        "        if col_to_match.startswith(fc):\n",
        "            return catchall_dict[fc]\n",
        "    raise Exception('no catchall column for variable')\n",
        "\n",
        "catchall_dict = get_catchall_dict(factor_cols, nlss_pca_df.columns)\n",
        "for col in nlss_pca_df.columns:\n",
        "    # DHS has no category - combine with \"other\" for appropriate group\n",
        "    if col not in set(rwi_weights['nlss_name']) and col in set(dummy_colnames):\n",
        "        catchall_col = get_catchall_column(col, factor_cols, catchall_dict)\n",
        "        nlss_pca_df[catchall_col] += nlss_pca_df[col]\n",
        "\n",
        "nlss_pca_df = nlss_pca_df[list(rwi_weights['nlss_name']) + ['hhid']]\n",
        "for col in nlss_pca_df[list(rwi_weights['nlss_name'])]:\n",
        "    vals = rwi_weights.loc[rwi_weights['nlss_name'] == col].iloc[0]\n",
        "    nlss_pca_df[col] = nlss_pca_df[col].apply(lambda x: vals['zero_weight'] if x == 0 else\n",
        "                                                        vals['one_weight'])\n",
        "\n",
        "nlss_pca_df['dhs_like_rwi'] = standardize(\n",
        "    nlss_pca_df[list(rwi_weights['nlss_name'])].sum(axis=1))\n",
        "nlss_rwi_dhs_like = nlss_pca_df[['dhs_like_rwi', 'hhid']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "cellView": "form",
        "id": "ioylNLClSPi9"
      },
      "outputs": [],
      "source": [
        "#@title Aggregate NLSS rwi over administrative units\n",
        "\n",
        "nlss_rwi_df = nlss_rwi_dhs_like\n",
        "nlss_rwi_col = 'dhs_like_rwi'\n",
        "\n",
        "# nlss_rwi_df = nlss_rwi_pca\n",
        "# nlss_rwi_col = 'survey_rwi_full'\n",
        "\n",
        "nlss_hhs = nlss_rwi_df.merge(nlss_data[['hhid', 'popw', 'ward', 'lga', 'state']])\\\n",
        "                      .rename({nlss_rwi_col: 'nlss_rwi'}, axis=1)\n",
        "nlss_hhs['nlss_rwi_w'] = nlss_hhs['nlss_rwi'] * nlss_hhs['popw']\n",
        "\n",
        "nlss_state = nlss_hhs.groupby('state')[['popw', 'nlss_rwi_w']].sum().reset_index()\n",
        "nlss_state['nlss_rwi'] = standardize(nlss_state['nlss_rwi_w'] / nlss_state['popw'])\n",
        "nlss_state = nlss_state[['state', 'nlss_rwi', 'popw']]\n",
        "\n",
        "nlss_lga = nlss_hhs.groupby('lga')[['nlss_rwi']].mean().reset_index()\n",
        "nlss_lga['nlss_rwi'] = standardize(nlss_lga['nlss_rwi'])\n",
        "\n",
        "nlss_ward = nlss_hhs.groupby('ward')[['nlss_rwi']].mean().reset_index()\n",
        "nlss_ward['nlss_rwi'] = standardize(nlss_ward['nlss_rwi'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "cellView": "form",
        "id": "X13lkB7SSPdu"
      },
      "outputs": [],
      "source": [
        "#@title Aggregate DHS rwi over administrative units\n",
        "dhs_eval['dhs_rwi_w'] = dhs_eval['dhs_rwi'] * dhs_eval['weight']\n",
        "\n",
        "dhs_state = dhs_eval.groupby('geo_state')[['dhs_rwi_w', 'weight']].sum().reset_index()\\\n",
        "                    .rename({'geo_state': 'state'}, axis=1)\n",
        "dhs_state['dhs_rwi'] = standardize(dhs_state['dhs_rwi_w'] / dhs_state['weight'])\n",
        "dhs_state = dhs_state[['state', 'dhs_rwi']]\n",
        "\n",
        "dhs_lga = dhs_eval.groupby('lga')[['dhs_rwi']].mean().reset_index()\n",
        "dhs_lga['dhs_rwi'] = standardize(dhs_lga['dhs_rwi'])\n",
        "\n",
        "dhs_ward = dhs_eval.groupby('ward')[['dhs_rwi']].mean().reset_index()\n",
        "dhs_ward['dhs_rwi'] = standardize(dhs_ward['dhs_rwi'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mLv1y0rSEDQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQNT7NH_ta_m"
      },
      "source": [
        "# Shared data & helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQYIbvcQa62Z",
        "outputId": "8051e4dc-017a-482b-d9e7-2c29e5b37f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.40532921993869897 0.08207280524503148\n"
          ]
        }
      ],
      "source": [
        "#@title Make poverty line df\n",
        "\n",
        "pl = nlss_data['pl'].iloc[0]\n",
        "ultra_pl = pl / 2\n",
        "\n",
        "def get_weighted_quantile(df, q_col, weight_col, out_col):\n",
        "    df = df.sort_values(q_col)\n",
        "    df['cum_weight'] = df[weight_col].cumsum()\n",
        "    total = df[weight_col].sum()\n",
        "    dedup = df.drop_duplicates(q_col, keep='last')\n",
        "    dedup[out_col] = dedup['cum_weight'] / total\n",
        "    return df.merge(dedup[[q_col, out_col]], on=q_col).drop('cum_weight', axis=1)\n",
        "\n",
        "nlss_data['poor'] = nlss_data.apply(\n",
        "    lambda x: 0 if x['totcons_adj'] > x['pl'] else 1, axis=1)\n",
        "nlss_data['ultrapoor'] = nlss_data.apply(\n",
        "    lambda x: 0 if x['totcons_adj'] > (x['pl'] / 2) else 1, axis=1)\n",
        "nlss_pls = nlss_hhs.merge(\n",
        "    nlss_data[['hhid', 'poor', 'ultrapoor', 'log_con']], on='hhid')\n",
        "\n",
        "poor_thresh = (nlss_pls['poor'] * nlss_pls['popw']).sum() \\\n",
        "    / nlss_pls['popw'].sum()\n",
        "ultrapoor_thresh = (nlss_pls['ultrapoor'] * nlss_pls['popw']).sum() \\\n",
        "    / nlss_pls['popw'].sum()\n",
        "print(poor_thresh, ultrapoor_thresh)\n",
        "\n",
        "nlss_pls = get_weighted_quantile(nlss_pls, 'nlss_rwi', 'popw', 'nlss_rwi_q')\n",
        "nlss_pls = nlss_pls.drop(['nlss_rwi', 'poor', 'ultrapoor', 'log_con'],\n",
        "                         axis=1)\n",
        "\n",
        "pop_reweight = states['pop'].sum() / nlss_pls['popw'].sum()\n",
        "\n",
        "nlss_pls['asset_poor'] = nlss_pls['nlss_rwi_q']\\\n",
        "    .apply(lambda x: 0 if x > poor_thresh else 1)\n",
        "nlss_pls['asset_ultrapoor'] = nlss_pls['nlss_rwi_q']\\\n",
        "    .apply(lambda x: 0 if x > ultrapoor_thresh else 1)\n",
        "\n",
        "nlss_pls['asset_poor_w'] = nlss_pls.apply(\n",
        "    lambda x: x['asset_poor'] * x['popw'] * pop_reweight, axis=1)\n",
        "nlss_pls['asset_ultrapoor_w'] = nlss_pls.apply(\n",
        "    lambda x: x['asset_ultrapoor'] * x['popw'] * pop_reweight, axis=1)\n",
        "\n",
        "total_poor = states['pop'].sum() * poor_thresh\n",
        "total_ultrapoor = states['pop'].sum() * ultrapoor_thresh\n",
        "total_nonpoor = states['pop'].sum() * (1 - poor_thresh)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "cellView": "form",
        "id": "s-H3T5wUa6y7"
      },
      "outputs": [],
      "source": [
        "#@title Use only regions where all sources have data\n",
        "roc_lgas = lgas[(lgas['lga'].isin(dhs_lga['lga'])) &\n",
        "                (lgas['lga'].isin(nlss_lga['lga']))]\n",
        "roc_wards = wards[(wards['ward'].isin(dhs_ward['ward'])) &\n",
        "                  (wards['ward'].isin(nlss_ward['ward']))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "cellView": "form",
        "id": "rNRXXzJluxEl"
      },
      "outputs": [],
      "source": [
        "#@title Augment df helper\n",
        "def augment_region_pl_df_uw(nlss_pls_reg):\n",
        "    nlss_pls_reg['cum_pop'] = nlss_pls_reg['pop'].cumsum()\n",
        "\n",
        "    nlss_pls_reg['asset_poor_w'] = nlss_pls_reg['pop'] * nlss_pls_reg['asset_poor']\n",
        "    nlss_pls_reg['asset_ultrapoor_w'] = nlss_pls_reg['pop'] * nlss_pls_reg['asset_ultrapoor']\n",
        "\n",
        "    nlss_pls_reg['asset_poor_inc'] = nlss_pls_reg['asset_poor_w'].cumsum() \\\n",
        "                                     / nlss_pls_reg['asset_poor_w'].sum()\n",
        "    nlss_pls_reg['asset_ultrapoor_inc'] = nlss_pls_reg['asset_ultrapoor_w'].cumsum() \\\n",
        "                                         / nlss_pls_reg['asset_ultrapoor_w'].sum()\n",
        "    nlss_pls_reg['asset_nonpoor_inc'] = (nlss_pls_reg['cum_pop'] -\n",
        "                                         nlss_pls_reg['asset_poor_w'].cumsum()) \\\n",
        "                                         / (nlss_pls_reg['pop'].sum() -\n",
        "                                            nlss_pls_reg['asset_poor_w'].sum())\n",
        "    nlss_pls_reg['asset_nonultrapoor_inc'] = (nlss_pls_reg['cum_pop'] -\n",
        "                                              nlss_pls_reg['asset_ultrapoor_w'].cumsum()) \\\n",
        "                                              / (nlss_pls_reg['pop'].sum() -\n",
        "                                                 nlss_pls_reg['asset_ultrapoor_w'].sum())\n",
        "    return nlss_pls_reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "cellView": "form",
        "id": "I9tuJXSiIEZy"
      },
      "outputs": [],
      "source": [
        "#@title Get ROC helper\n",
        "def get_roc(df):\n",
        "    keep_cols = ['asset_nonpoor_inc', 'asset_poor_inc',\n",
        "                 'asset_ultrapoor_inc', 'asset_nonultrapoor_inc']\n",
        "    dummy_row = pd.Series(['dummy'] + [0] * (len(df.columns) - 1),\n",
        "                          index=df.columns)\n",
        "    df = df.append(dummy_row, ignore_index=True)\n",
        "\n",
        "    df = df[keep_cols].sort_values('asset_nonpoor_inc')\n",
        "    poor = auc(df['asset_nonpoor_inc'], df['asset_poor_inc'])\n",
        "    df = df.sort_values('asset_nonultrapoor_inc')\n",
        "    ultrapoor = auc(df['asset_nonultrapoor_inc'], df['asset_ultrapoor_inc'])\n",
        "    print('poor', round(poor, 3), 'very poor', round(ultrapoor, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "cellView": "form",
        "id": "nB-ICr4_P-F9"
      },
      "outputs": [],
      "source": [
        "#@title Correlation CI helpers\n",
        "# http://faculty.washington.edu/gloftus/P317-318/Useful_Information/r_to_z/PearsonrCIs.pdf\n",
        "\n",
        "def r_to_z(r):\n",
        "    return 0.5 * np.log((1 + r) / (1 - r))\n",
        "\n",
        "def z_to_r(z):\n",
        "    return (np.exp(2 * z) - 1) / (np.exp(2 * z) + 1)\n",
        "\n",
        "def get_r_ci(df, c1, c2, rounded=True):\n",
        "    r, p = pearsonr(df[c1], df[c2])\n",
        "    z = r_to_z(r)\n",
        "    std = np.sqrt(1 / (len(df) - 3))\n",
        "    if rounded:\n",
        "        return round(r, 3), p, (round(z_to_r(z - 1.96 * std), 3), round(z_to_r(z + 1.96 * std), 3))\n",
        "    return r, (p, z_to_r(z - 1.96 * std), z_to_r(z + 1.96 * std))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "wOA5KTKetY7g"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoCxW6LJa7LN"
      },
      "source": [
        "# Do mean targeting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "cellView": "form",
        "id": "B2sO6wq4a6vz"
      },
      "outputs": [],
      "source": [
        "#@title NLSS state level targeting DF\n",
        "\n",
        "total_poor = states['pop'].sum() * poor_thresh\n",
        "total_ultrapoor = states['pop'].sum() * ultrapoor_thresh\n",
        "total_nonpoor = states['pop'].sum() * (1 - poor_thresh)\n",
        "\n",
        "nlss_pls_state = nlss_pls.groupby('state')\\\n",
        "    [['nlss_rwi_w', 'asset_poor_w', 'asset_ultrapoor_w']].sum().reset_index()\n",
        "nlss_pls_state = nlss_pls_state.merge(states)\n",
        "\n",
        "nlss_pls_state['nlss_rwi'] = nlss_pls_state['nlss_rwi_w'] \\\n",
        "    / nlss_pls_state['pop']\n",
        "nlss_pls_state = nlss_pls_state.sort_values(by='nlss_rwi')\\\n",
        "                               .drop('nlss_rwi_w', axis=1)\n",
        "nlss_pls_state['cum_pop'] = nlss_pls_state['pop'].cumsum()\n",
        "\n",
        "nlss_pls_state['asset_poor_inc'] = nlss_pls_state['asset_poor_w'].cumsum() \\\n",
        "    / total_poor\n",
        "nlss_pls_state['asset_ultrapoor_inc'] = nlss_pls_state['asset_ultrapoor_w']\\\n",
        "    .cumsum() / total_ultrapoor\n",
        "nlss_pls_state['asset_nonpoor_inc'] = (nlss_pls_state['cum_pop'] -\n",
        "    nlss_pls_state['asset_poor_w'].cumsum()) \\\n",
        "    / (states['pop'].sum() * (1 - poor_thresh))\n",
        "nlss_pls_state['asset_nonultrapoor_inc'] = (nlss_pls_state['cum_pop'] -\n",
        "    nlss_pls_state['asset_ultrapoor_w'].cumsum()) \\\n",
        "    / (states['pop'].sum() * (1 - ultrapoor_thresh))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "uz4NZ1naTH9i"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "cellView": "form",
        "id": "WSu6Kiqma6qt"
      },
      "outputs": [],
      "source": [
        "#@title LGA/ward poverty line df helper\n",
        "\n",
        "# def get_region_pl_df_uw(pop_df, groupby_col, pls_df=nlss_pls):\n",
        "#     nlss_pls_means = pls_df.groupby(groupby_col)[['asset_poor', 'asset_ultrapoor']]\\\n",
        "#                            .mean()\\\n",
        "#                            .reset_index()\n",
        "#     nlss_pls_reg = pls_df.groupby(groupby_col)[['nlss_rwi_w', 'popw']]\\\n",
        "#                          .sum()\\\n",
        "#                          .reset_index()\\\n",
        "#                          .merge(pop_df[[groupby_col, 'pop']])\\\n",
        "#                          .merge(nlss_pls_means)\n",
        "#     print(len(nlss_pls_reg))\n",
        "#     nlss_pls_reg['nlss_rwi'] = nlss_pls_reg['nlss_rwi_w'] / nlss_pls_reg['popw']\n",
        "#     nlss_pls_reg = nlss_pls_reg.sort_values(by='nlss_rwi')\\\n",
        "#                                .drop('nlss_rwi_w', axis=1)\n",
        "#     return augment_region_pl_df_uw(nlss_pls_reg)\n",
        "    \n",
        "def get_region_pl_df_uw(pop_df, groupby_col, rwi_col_in='nlss_rwi_w',\n",
        "                        rwi_col_out='nlss_rwi', pls_df=nlss_pls):\n",
        "    nlss_pls_means = pls_df.groupby(groupby_col)[['asset_poor', 'asset_ultrapoor']]\\\n",
        "                           .mean()\\\n",
        "                           .reset_index()\n",
        "    nlss_pls_reg = pls_df.groupby(groupby_col)[[rwi_col_in, 'popw']]\\\n",
        "                         .sum()\\\n",
        "                         .reset_index()\\\n",
        "                         .merge(pop_df[[groupby_col, 'pop']])\\\n",
        "                         .merge(nlss_pls_means)\n",
        "    print(len(nlss_pls_reg))\n",
        "    nlss_pls_reg[rwi_col_out] = nlss_pls_reg[rwi_col_in] / nlss_pls_reg['popw']\n",
        "    nlss_pls_reg = nlss_pls_reg.sort_values(by=rwi_col_out)\\\n",
        "                               .drop(rwi_col_in, axis=1)\n",
        "    return augment_region_pl_df_uw(nlss_pls_reg)\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnqsUYUwa6n2",
        "outputId": "e6c121fa-4e10-41eb-e083-71f4db9b2a0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "597\n",
            "Asset poor frac, lgas: 0.408\n",
            "Asset very poor frac, lgas: 0.0912\n",
            "464\n",
            "Asset poor frac, wards: 0.29\n",
            "Asset very poor frac, wards: 0.0662\n"
          ]
        }
      ],
      "source": [
        "#@title NLSS LGA and ward level targeting DFs\n",
        "# NLSS poverty lines, LGA\n",
        "nlss_pls_lga = get_region_pl_df_uw(roc_lgas, 'lga')\n",
        "print('Asset poor frac, lgas:', round(nlss_pls_lga['asset_poor_w'].sum() /\n",
        "                                nlss_pls_lga['pop'].sum(), 3))\n",
        "print('Asset very poor frac, lgas:', round(nlss_pls_lga['asset_ultrapoor_w'].sum() /\n",
        "                                     nlss_pls_lga['pop'].sum(), 4))\n",
        "\n",
        "# NLSS poverty lines, ward\n",
        "nlss_pls_ward = get_region_pl_df_uw(roc_wards, 'ward')\n",
        "print('Asset poor frac, wards:', round(nlss_pls_ward['asset_poor_w'].sum() /\n",
        "                                nlss_pls_ward['pop'].sum(), 3))\n",
        "print('Asset very poor frac, wards:', round(nlss_pls_ward['asset_ultrapoor_w'].sum() /\n",
        "                                     nlss_pls_ward['pop'].sum(), 4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "YPzjrBPUei7P"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "cellView": "form",
        "id": "gU6VjWECd-8s"
      },
      "outputs": [],
      "source": [
        "# @title Get DIDL data for ROC plot\n",
        "\n",
        "def get_inc_ex(pls_reg):\n",
        "    pls_reg['cum_pop'] = pls_reg['pop'].cumsum()\n",
        "\n",
        "    pls_reg['asset_poor_inc'] = pls_reg['asset_poor_w'].cumsum() \\\n",
        "                                / pls_reg['asset_poor_w'].sum()\n",
        "    pls_reg['asset_ultrapoor_inc'] = pls_reg['asset_ultrapoor_w'].cumsum() \\\n",
        "                                     / pls_reg['asset_ultrapoor_w'].sum()\n",
        "    pls_reg['asset_nonpoor_inc'] = (pls_reg['cum_pop'] - pls_reg['asset_poor_w'].cumsum()) \\\n",
        "                                    / (pls_reg['pop'].sum() - pls_reg['asset_poor_w'].sum())\n",
        "    pls_reg['asset_nonultrapoor_inc'] = (pls_reg['cum_pop'] -\n",
        "                                         pls_reg['asset_ultrapoor_w'].cumsum()) \\\n",
        "                                         / (pls_reg['pop'].sum() -\n",
        "                                         pls_reg['asset_ultrapoor_w'].sum())\n",
        "    return pls_reg\n",
        "\n",
        "def get_didl_pl_df(groupby_col, didl_reg, nlss_pls_reg):\n",
        "    didl_pls_reg = nlss_pls_reg.merge(didl_reg[[groupby_col, 'didl_orig_rwi']])\\\n",
        "                               .sort_values(by='didl_orig_rwi')\n",
        "    return get_inc_ex(didl_pls_reg)\n",
        "    \n",
        "\n",
        "didl_pls_state = get_didl_pl_df('state', didl_orig_state, nlss_pls_state)\n",
        "didl_pls_lga = get_didl_pl_df('lga', didl_orig_lga, nlss_pls_lga)\n",
        "didl_pls_ward = get_didl_pl_df('ward', didl_orig_ward, nlss_pls_ward)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "cellView": "form",
        "id": "rVtJ-T7Xa6lF"
      },
      "outputs": [],
      "source": [
        "#@title Get DHS data for ROC plot\n",
        "\n",
        "def get_dhs_pl_df(groupby_col, dhs_reg, nlss_pls_reg):\n",
        "    dhs_pls_reg = nlss_pls_reg.merge(dhs_reg[[groupby_col, 'dhs_rwi']])\\\n",
        "                              .sort_values(by='dhs_rwi')\n",
        "    return get_inc_ex(dhs_pls_reg)\n",
        "\n",
        "\n",
        "common_lgas = dhs_lga.loc[dhs_lga['lga'].isin(nlss_lga['lga']), 'lga'].to_list()\n",
        "nlss_dhs_pls = nlss_pls[nlss_pls['lga'].isin(common_lgas)]\n",
        "\n",
        "dhs_pls_state = get_dhs_pl_df('state', dhs_state, nlss_pls_state)\n",
        "dhs_pls_lga = get_dhs_pl_df('lga', dhs_lga, nlss_pls_lga)\n",
        "dhs_pls_ward = get_dhs_pl_df('ward', dhs_ward, nlss_pls_ward)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "cellView": "form",
        "id": "mCffU0mSbPBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2302f151-9088-4d0c-d13a-e259d01ecf07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.687\n"
          ]
        }
      ],
      "source": [
        "#@title Make imputed DHS df -- LGAs\n",
        "def impute_lga_with_state(row):\n",
        "    drop_lga_df = dhs_eval.loc[(dhs_eval['lga'] != row['lga']) &\n",
        "                               (dhs_eval['geo_state'] == row['state'])]\n",
        "    return drop_lga_df['dhs_rwi_w'].sum() / drop_lga_df['weight'].sum()\n",
        "\n",
        "dhs_eval['dhs_rwi_w'] = dhs_eval['weight'] * standardize(dhs_eval['dhs_rwi'])\n",
        "dhs_lga_impute = dhs_lga.merge(lgas[['lga', 'state']]) #, how='right')\n",
        "\n",
        "dhs_lga_impute['imputed_rwi'] = dhs_lga_impute.apply(impute_lga_with_state, axis=1)\n",
        "\n",
        "print(round(pearsonr(dhs_lga_impute['imputed_rwi'], dhs_lga_impute['dhs_rwi'])[0], 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "Tvnz0viobO-C",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6936f1d-486c-4a45-d7f2-c811d1c2518c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1218\n",
            "0.689\n"
          ]
        }
      ],
      "source": [
        "#@title Make imputed DHS df -- wards\n",
        "def impute_ward_with_lga(row):\n",
        "    drop_ward_df = dhs_eval.loc[(dhs_eval['ward'] != row['ward']) &\n",
        "                                (dhs_eval['lga'] == row['lga'])]\n",
        "    if len(drop_ward_df) == 0:\n",
        "        return None\n",
        "    return drop_ward_df['dhs_rwi'].sum() / drop_ward_df['weight'].count()\n",
        "\n",
        "dhs_eval['dhs_rwi'] = standardize(dhs_eval['dhs_rwi'])\n",
        "dhs_ward_impute = dhs_ward.merge(wards[['ward', 'lga']]) #, how='right')\n",
        "# dhs_ward_impute = dhs_ward_impute[dhs_ward_impute['ward'].isin(nlss_ward['ward'])]\n",
        "\n",
        "dhs_ward_impute['imputed_rwi'] = dhs_ward_impute.apply(impute_ward_with_lga, axis=1)\n",
        "\n",
        "dhs_ward_impute = dhs_ward_impute.merge(dhs_lga_impute[['lga', 'imputed_rwi']].\n",
        "                                        rename({'imputed_rwi': 'state_rwi'}, axis=1),\n",
        "                                        on='lga')\n",
        "print(len(dhs_ward_impute))\n",
        "dhs_ward_impute.loc[dhs_ward_impute['imputed_rwi'].isna(), 'imputed_rwi'] = \\\n",
        "    dhs_ward_impute.loc[dhs_ward_impute['imputed_rwi'].isna(), 'state_rwi']\n",
        "\n",
        "print(round(pearsonr(dhs_ward_impute['imputed_rwi'], dhs_ward_impute['dhs_rwi'])[0], 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "cellView": "form",
        "id": "GK31vzT2bO6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea52a93-7563-46cc-ad4d-ad8f8f06dc3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110 597\n"
          ]
        }
      ],
      "source": [
        "#@title Bootstrap LGAs w imputation, DHS\n",
        "np.random.seed(123)\n",
        "\n",
        "def get_random_roc(groupby_col, pop_df, n_to_replace, random_df,\n",
        "                   nlss_pls, rwi_col='dhs_rwi'):\n",
        "    replace = random_df.sample(n_to_replace)[groupby_col].to_list()\n",
        "    random_df['rwi'] = random_df[rwi_col]\n",
        "    random_df.loc[random_df[groupby_col].isin(replace), 'rwi'] = \\\n",
        "        random_df.loc[random_df[groupby_col].isin(replace), 'imputed_rwi']    \n",
        "    dhs_pls_reg = nlss_pls.merge(random_df[[groupby_col, 'rwi']])\\\n",
        "                          .sort_values(by='rwi')\n",
        "    \n",
        "    return get_inc_ex(dhs_pls_reg)\n",
        "\n",
        "def get_auc(df, col1, col2):\n",
        "    return auc(df.sort_values(col1)[col1], df.sort_values(col1)[col2])\n",
        "\n",
        "n_to_replace = round((1 - (len(dhs_lga_impute) / len(lgas))) * len(dhs_pls_lga))\n",
        "dhs_lga_impute = dhs_lga_impute[dhs_lga_impute['lga'].isin(roc_lgas['lga'])]\n",
        "print(n_to_replace, len(dhs_lga_impute))\n",
        "\n",
        "lga_output = []\n",
        "b = 1000\n",
        "for i in range(b):\n",
        "    lga_pls_i = get_random_roc('lga', lgas, n_to_replace, dhs_lga_impute, nlss_pls_lga)\n",
        "    lga_output += [(get_auc(lga_pls_i, 'asset_nonpoor_inc', 'asset_poor_inc'),\n",
        "                    get_auc(lga_pls_i, 'asset_nonultrapoor_inc', 'asset_ultrapoor_inc'),\n",
        "                    lga_pls_i)]\n",
        "\n",
        "noisy_dhs_lga_poor = sorted(lga_output, key=lambda x: x[0])[int(b / 2) - 1][2]\n",
        "noisy_dhs_lga_ultrapoor = sorted(lga_output, key=lambda x: x[1])[int(b / 2) - 1][2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "cellView": "form",
        "id": "6tagaMT4bO3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76390c22-81a8-4b59-bf19-917806fe86b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400 464\n"
          ]
        }
      ],
      "source": [
        "#@title Bootstrap wards w imputation, DHS\n",
        "np.random.seed(123)\n",
        "\n",
        "n_to_replace = round((1 - (len(dhs_ward) / len(wards))) * len(dhs_pls_ward))\n",
        "dhs_ward_impute = dhs_ward_impute[dhs_ward_impute['ward'].isin(roc_wards['ward'])]\n",
        "print(n_to_replace, len(dhs_ward_impute))\n",
        "\n",
        "ward_output = []\n",
        "for i in range(b):\n",
        "    ward_pls_i = get_random_roc('ward', wards, n_to_replace, dhs_ward_impute, nlss_pls_ward)\n",
        "    ward_output += [(get_auc(ward_pls_i, 'asset_nonpoor_inc', 'asset_poor_inc'),\n",
        "                     get_auc(ward_pls_i, 'asset_nonultrapoor_inc', 'asset_ultrapoor_inc'),\n",
        "                     ward_pls_i)]\n",
        "\n",
        "noisy_dhs_ward_poor = sorted(ward_output, key=lambda x: x[0])[int(b / 2) - 1][2]\n",
        "noisy_dhs_ward_ultrapoor = sorted(ward_output, key=lambda x: x[1])[int(b / 2) - 1][2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "Bc2Fu8TvKNWC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "id": "X4cjUdOYf66w",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56900537-2685-40b6-8ccf-9243c683638a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.646896384628388, 4.589551985764816e-72)"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ],
      "source": [
        "#@title Write csvs to make figures in R\n",
        "imputed_wards = dhs_ward_impute[['ward', 'imputed_rwi']].merge(nlss_pls_ward[['ward', 'nlss_rwi']])\n",
        "imputed_wards['imputed_rwi'] = standardize(imputed_wards['imputed_rwi'])\n",
        "imputed_wards['nlss_rwi'] = standardize(imputed_wards['nlss_rwi'])\n",
        "imputed_wards.to_csv('dhs_imputed_rwi_ward.csv', index=False)\n",
        "\n",
        "imputed_lgas = dhs_lga_impute[['lga', 'imputed_rwi']].merge(nlss_pls_lga[['lga', 'nlss_rwi']])\n",
        "imputed_lgas['imputed_rwi'] = standardize(imputed_lgas['imputed_rwi'])\n",
        "imputed_lgas['nlss_rwi'] = standardize(imputed_lgas['nlss_rwi'])\n",
        "imputed_lgas.to_csv('dhs_imputed_rwi_lga.csv', index=False)\n",
        "\n",
        "pearsonr(imputed_lgas['imputed_rwi'], imputed_lgas['nlss_rwi'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "id": "nGI1fhnRHZFA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzIphYDjkRQl"
      },
      "source": [
        "# Do fraction poor targeting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NLdQtXH9bOw9"
      },
      "outputs": [],
      "source": [
        "#@title NLSS state level targeting DF, target by frac\n",
        "\n",
        "# poor_thresh = (nlss_pls['poor'] * nlss_pls['popw']).sum() \\\n",
        "#     / nlss_pls['popw'].sum()\n",
        "# ultrapoor_thresh = (nlss_pls['ultrapoor'] * nlss_pls['popw']).sum() \\\n",
        "#     / nlss_pls['popw'].sum()\n",
        "# print(poor_thresh, ultrapoor_thresh)\n",
        "\n",
        "total_poor = states['pop'].sum() * poor_thresh\n",
        "total_ultrapoor = states['pop'].sum() * ultrapoor_thresh\n",
        "total_nonpoor = states['pop'].sum() * (1 - poor_thresh)\n",
        "\n",
        "nlss_pls_state = nlss_pls.groupby('state')\\\n",
        "    [['nlss_rwi_w', 'asset_poor_w', 'asset_ultrapoor_w']].sum().reset_index()\n",
        "nlss_pls_state = nlss_pls_state.merge(states)\n",
        "\n",
        "nlss_pls_state['frac_asset_poor'] = nlss_pls_state['asset_poor_w'] / \\\n",
        "    nlss_pls_state['pop']\n",
        "nlss_pls_state['frac_asset_ultrapoor'] = nlss_pls_state['asset_ultrapoor_w'] / \\\n",
        "    nlss_pls_state['pop']\n",
        "\n",
        "# Get errors of inc/ex for targeting based on % poor\n",
        "\n",
        "def get_sort_by_frac_inc_ex(df, poverty_str, total, thresh):\n",
        "    df = df.sort_values(by='frac_asset_%s' % poverty_str, ascending=False)\n",
        "    df['cum_pop_sort_%s' % poverty_str] = df['pop'].cumsum()\n",
        "    df['asset_%s_inc' % poverty_str] = df['asset_%s_w' % poverty_str].cumsum() \\\n",
        "        / total\n",
        "    df['asset_non%s_inc' % poverty_str] = (df['cum_pop_sort_%s' % poverty_str] -\n",
        "        df['asset_%s_w' % poverty_str].cumsum()) \\\n",
        "        / (states['pop'].sum() * (1 - thresh))\n",
        "    return df\n",
        "\n",
        "nlss_pls_state = get_sort_by_frac_inc_ex(nlss_pls_state, 'poor',\n",
        "                                         total_poor, poor_thresh)\n",
        "nlss_pls_state = get_sort_by_frac_inc_ex(nlss_pls_state, 'ultrapoor',\n",
        "                                         total_ultrapoor, ultrapoor_thresh)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uCkIXsXKqllK"
      },
      "outputs": [],
      "source": [
        "#@title LGA/ward poverty line df helper, target by frac\n",
        "\n",
        "def get_region_pl_df_frac(pop_df, groupby_col, pls_df=nlss_pls):\n",
        "    nlss_pls_means = pls_df.groupby(groupby_col)[['asset_poor', 'asset_ultrapoor']]\\\n",
        "                            .mean()\\\n",
        "                            .reset_index()\\\n",
        "                            .merge(pop_df[[groupby_col, 'pop']])\n",
        "\n",
        "    ultrapoor_cols = ['asset_ultrapoor_inc', 'asset_nonultrapoor_inc']\n",
        "    poor_df = augment_region_pl_df_uw(\n",
        "        nlss_pls_means.sort_values('asset_poor', ascending=False))\\\n",
        "        .drop(ultrapoor_cols, axis=1)\n",
        "    ultrapoor_df = augment_region_pl_df_uw(\n",
        "        nlss_pls_means.sort_values('asset_ultrapoor', ascending=False))\n",
        "    return poor_df.merge(ultrapoor_df[[groupby_col] + ultrapoor_cols])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_J2hICvcqlhv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8664df6d-cb3f-46cc-9ce5-d905c129090e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asset poor frac, lgas: 0.408\n",
            "Asset very poor frac, lgas: 0.0912\n",
            "Asset poor frac, wards: 0.29\n",
            "Asset very poor frac, wards: 0.0662\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(597, 464, 597)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "#@title NLSS LGA and ward level targeting DFs, target by frac\n",
        "# NLSS poverty lines, LGA\n",
        "nlss_pls_lga = get_region_pl_df_frac(roc_lgas, 'lga')\n",
        "print('Asset poor frac, lgas:', round(nlss_pls_lga['asset_poor_w'].sum() /\n",
        "                                nlss_pls_lga['pop'].sum(), 3))\n",
        "print('Asset very poor frac, lgas:', round(nlss_pls_lga['asset_ultrapoor_w'].sum() /\n",
        "                                     nlss_pls_lga['pop'].sum(), 4))\n",
        "\n",
        "# NLSS poverty lines, ward\n",
        "nlss_pls_ward = get_region_pl_df_frac(roc_wards, 'ward')\n",
        "print('Asset poor frac, wards:', round(nlss_pls_ward['asset_poor_w'].sum() /\n",
        "                                nlss_pls_ward['pop'].sum(), 3))\n",
        "print('Asset very poor frac, wards:', round(nlss_pls_ward['asset_ultrapoor_w'].sum() /\n",
        "                                     nlss_pls_ward['pop'].sum(), 4))\n",
        "\n",
        "len(nlss_pls_lga), len(nlss_pls_ward), len(roc_lgas)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CS0rIX_g0rei"
      },
      "outputs": [],
      "source": [
        "#@title Helper to estimate # poor per region from DIDL data\n",
        "def n_poor(region, tiles, region_col, col_to_weight):\n",
        "    def get_intersection_area(df):\n",
        "            return df['geometry'].intersection(df['geometry_geom']).area\n",
        "\n",
        "    overlaps = gpd.sjoin(region, tiles, how='right', op='intersects')\\\n",
        "                    .reset_index()\\\n",
        "                    .rename({'index': 'tile_index'}, axis=1)\n",
        "    overlaps = overlaps.merge(region[['geometry', region_col]]\\\n",
        "                                .rename({'geometry': 'geometry_' + region_col}, axis=1),\n",
        "                                on=region_col)\n",
        "    edge_tiles = overlaps[overlaps.duplicated(subset=['tile_index'], keep=False)]\n",
        "    center_tiles = overlaps.drop_duplicates(subset=['tile_index'], keep=False)\n",
        "\n",
        "    edge_tiles['overlap_frac'] = edge_tiles.apply(lambda x: (x['geometry'].intersection(\n",
        "                                                    x['geometry_' + region_col]).area /\n",
        "                                                    x['geometry'].area),\n",
        "                                                    axis=1)\n",
        "    center_tiles['overlap_frac'] = 1\n",
        "    overlaps = pd.concat([edge_tiles, center_tiles])\n",
        "\n",
        "    overlaps['weighted_col'] = overlaps[col_to_weight] * overlaps['overlap_frac']\n",
        "\n",
        "    return overlaps.groupby(region_col)[['weighted_col']]\\\n",
        "                        .sum()\\\n",
        "                        .reset_index()\\\n",
        "                        .rename({'weighted_col': col_to_weight}, axis=1)\\\n",
        "                        .merge(region[['geometry', region_col]], on=region_col)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "O3nCiN3dqlVH"
      },
      "outputs": [],
      "source": [
        "#@title Rank regions by fraction poor, DIDL\n",
        "\n",
        "if False: # very slow -- save and re-use\n",
        "    didl_tiles = get_weighted_quantile(didl_orig_all, 'estimated_rwi', 'pop', 'rwi_q')\n",
        "    # didl_tiles = gpd.read_file(NOT_INC_DATA_PATH + 'estimates/didl_tile_wealth_quantiles.geojson')\\\n",
        "    #         .rename({'estimated_': 'estimated_rwi'}, axis=1)\n",
        "\n",
        "    didl_tiles['poor'] = didl_tiles.apply(\n",
        "        lambda x: x['pop'] if x['rwi_q'] < poor_thresh else 0, axis=1)\n",
        "    didl_tiles['ultrapoor'] = didl_tiles.apply(\n",
        "        lambda x: x['pop'] if x['rwi_q'] < ultrapoor_thresh else 0, axis=1)\n",
        "\n",
        "def get_n_poor_region_df_didl(region_df, region_col):\n",
        "\n",
        "    n_poor_df = n_poor(region_df[[region_col, 'geometry']], didl_tiles, region_col, 'poor')\n",
        "    n_poor_df = n_poor_df.merge(region_df[[region_col, 'pop']])\n",
        "    n_poor_df['frac_poor'] = n_poor_df['poor'] / n_poor_df['pop']\n",
        "\n",
        "    n_ultrapoor_df = n_poor(region_df[[region_col, 'geometry']], didl_tiles,\n",
        "                                region_col, 'ultrapoor')\n",
        "    didl_orig_reg = n_poor_df.merge(n_ultrapoor_df[[region_col, 'ultrapoor']])\n",
        "    didl_orig_reg['frac_ultrapoor'] = didl_orig_reg['ultrapoor'] \\\n",
        "        / didl_orig_reg['pop']\n",
        "    return didl_orig_reg.drop(['poor', 'ultrapoor'], axis=1)\n",
        "\n",
        "poor_frac_path = NOT_INC_DATA_PATH + 'generated_estimates/fraction/'\n",
        "if False: # slow -- use saved data\n",
        "    didl_orig_state = get_n_poor_region_df_didl(states, 'state')\n",
        "\n",
        "    didl_orig_lga = get_n_poor_region_df_didl(lgas, 'lga')\n",
        "    didl_orig_lga.drop('geometry', axis=1)\\\n",
        "                .to_csv(poor_frac_path + 'didl_lga_poor_frac.csv', index=False)\n",
        "\n",
        "    didl_orig_ward = get_n_poor_region_df_didl(wards, 'ward')\n",
        "    didl_orig_ward.drop('geometry', axis=1)\\\n",
        "                .to_csv(poor_frac_path + 'didl_ward_poor_frac.csv', index=False)\n",
        "\n",
        "didl_orig_state = pd.read_csv(poor_frac_path + 'didl_state_poor_frac.csv')\n",
        "didl_orig_lga = pd.read_csv(poor_frac_path + 'didl_lga_poor_frac.csv')\n",
        "didl_orig_ward = pd.read_csv(poor_frac_path + 'didl_ward_poor_frac.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nyF3FYTXFZvi"
      },
      "outputs": [],
      "source": [
        "#@title Helper for poverty line dfs, DIDL & DHS, frac poor\n",
        "def get_inc_ex_frac(pls_reg, target):\n",
        "    pls_reg['cum_pop'] = pls_reg['pop'].cumsum()\n",
        "\n",
        "    pls_reg['asset_%s_inc' % target] = \\\n",
        "        pls_reg['asset_%s_w' % target].cumsum() /\\\n",
        "        pls_reg['asset_%s_w' % target].sum()\n",
        "    pls_reg['asset_non%s_inc' % target] = \\\n",
        "        (pls_reg['cum_pop'] - pls_reg['asset_%s_w' % target].cumsum()) /\\\n",
        "        (pls_reg['pop'].sum() - pls_reg['asset_%s_w' % target].sum())\n",
        "\n",
        "    return pls_reg\n",
        "\n",
        "def get_pl_df_frac_poor(groupby_col, didl_reg, nlss_pls_reg):\n",
        "    sort_col = 'frac_poor'\n",
        "    pls_poor = nlss_pls_reg.merge(didl_reg[[groupby_col, sort_col]])\\\n",
        "                           .sort_values(by=sort_col, ascending=False)\n",
        "    pls_poor = get_inc_ex_frac(pls_poor, 'poor')\n",
        "\n",
        "    sort_col = 'frac_ultrapoor'\n",
        "    pls_ultrapoor = nlss_pls_reg.merge(didl_reg[[groupby_col, sort_col]])\\\n",
        "                                .sort_values(by=sort_col, ascending=False)\n",
        "    pls_ultrapoor = get_inc_ex_frac(pls_ultrapoor, 'ultrapoor')\n",
        "\n",
        "    return pls_poor[[groupby_col, 'asset_poor_w', 'pop', 'asset_poor_inc',\n",
        "                     'asset_nonpoor_inc', 'frac_poor']].merge(\n",
        "           pls_ultrapoor[[groupby_col, 'asset_ultrapoor_w',\n",
        "                          'asset_ultrapoor_inc', 'asset_nonultrapoor_inc',\n",
        "                          'frac_ultrapoor']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0a2dYY60qleG"
      },
      "outputs": [],
      "source": [
        "#@title Get DIDL data for ROC plot\n",
        "\n",
        "pl_cols = ['asset_poor_w', 'asset_ultrapoor_w', 'pop']\n",
        "didl_pls_state = get_pl_df_frac_poor('state', didl_orig_state, nlss_pls_state[['state'] + pl_cols])\n",
        "didl_pls_lga = get_pl_df_frac_poor('lga', didl_orig_lga, nlss_pls_lga[['lga'] + pl_cols])\n",
        "didl_pls_ward = get_pl_df_frac_poor('ward', didl_orig_ward, nlss_pls_ward[['ward'] + pl_cols])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BlsJDkaH9z1z"
      },
      "outputs": [],
      "source": [
        "#@title Get DHS data for ROC plot\n",
        "dhs_poor_frac = get_weighted_quantile(dhs_eval, 'dhs_rwi', 'weight', 'rwi_q')\n",
        "dhs_poor_frac['poor'] = dhs_poor_frac.apply(\n",
        "        lambda x: x['weight'] if x['rwi_q'] < poor_thresh else 0, axis=1)\n",
        "dhs_poor_frac['ultrapoor'] = dhs_poor_frac.apply(\n",
        "    lambda x: x['weight'] if x['rwi_q'] < ultrapoor_thresh else 0, axis=1)\n",
        "\n",
        "def get_n_poor_region_df_dhs(poor_frac_df, region_col):\n",
        "    df = poor_frac_df.groupby(region_col)[['poor', 'ultrapoor', 'weight']]\\\n",
        "                     .sum().reset_index()\n",
        "    df['frac_poor'] = df['poor'] / df['weight']\n",
        "    df['frac_ultrapoor'] = df['ultrapoor'] / df['weight']\n",
        "\n",
        "    return df[[region_col, 'frac_poor', 'frac_ultrapoor']]\n",
        "\n",
        "dhs_state = get_n_poor_region_df_dhs(dhs_poor_frac, 'geo_state').rename(\n",
        "    {'geo_state': 'state'}, axis=1)\n",
        "dhs_lga = get_n_poor_region_df_dhs(dhs_poor_frac, 'lga')\n",
        "dhs_ward = get_n_poor_region_df_dhs(dhs_poor_frac, 'ward')\n",
        "\n",
        "# dhs_pls_state = get_dhs_pl_df('state', dhs_state, nlss_pls_state)\n",
        "# dhs_pls_lga = get_dhs_pl_df('lga', dhs_lga, nlss_pls_lga)\n",
        "# dhs_pls_ward = get_dhs_pl_df('ward', dhs_ward, nlss_pls_ward)\n",
        "\n",
        "dhs_pls_state = get_pl_df_frac_poor('state', dhs_state, nlss_pls_state[['state'] + pl_cols])\n",
        "dhs_pls_lga = get_pl_df_frac_poor('lga', dhs_lga, nlss_pls_lga[['lga'] + pl_cols])\n",
        "dhs_pls_ward = get_pl_df_frac_poor('ward', dhs_ward, nlss_pls_ward[['ward'] + pl_cols])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mTyxcwuTUGmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_b--l4bczj0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3078579-0bef-4ca7-be2b-10cc26829f3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.684\n",
            "0.61\n"
          ]
        }
      ],
      "source": [
        "# @title Make imputed DHS df -- LGAs, frac poor\n",
        "def impute_lga_with_state(row, impute_col):\n",
        "    drop_lga_df = dhs_poor_frac.loc[(dhs_poor_frac['lga'] != row['lga']) &\n",
        "                                    (dhs_poor_frac['geo_state'] == row['state'])]\n",
        "    return drop_lga_df[impute_col].sum() / drop_lga_df['weight'].sum()\n",
        "\n",
        "dhs_lga_impute = dhs_lga.merge(lgas[['lga', 'state']])\n",
        "dhs_lga_impute['imputed_frac_poor'] = dhs_lga_impute.apply(lambda x:\n",
        "    impute_lga_with_state(x, 'poor'), axis=1)\n",
        "dhs_lga_impute['imputed_frac_ultrapoor'] = dhs_lga_impute.apply(lambda x:\n",
        "    impute_lga_with_state(x, 'ultrapoor'), axis=1)\n",
        "\n",
        "print(round(pearsonr(dhs_lga_impute['imputed_frac_poor'],\n",
        "                     dhs_lga_impute['frac_poor'])[0], 3))\n",
        "print(round(pearsonr(dhs_lga_impute['imputed_frac_ultrapoor'],\n",
        "                     dhs_lga_impute['frac_ultrapoor'])[0], 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MZw5yDOA9zty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5203af03-6b32-44a4-ba8b-971c0a386289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.632\n",
            "0.503\n"
          ]
        }
      ],
      "source": [
        "#@title Make imputed DHS df -- wards, frac poor\n",
        "def impute_ward_with_lga(row, impute_col):\n",
        "    drop_ward_df = dhs_poor_frac.loc[(dhs_poor_frac['ward'] != row['ward']) &\n",
        "                                     (dhs_poor_frac['lga'] == row['lga'])]\n",
        "    if len(drop_ward_df) == 0:\n",
        "        return None\n",
        "\n",
        "    return drop_ward_df[impute_col].sum() / drop_ward_df['weight'].sum()\n",
        "\n",
        "dhs_ward_impute = dhs_ward.merge(wards[['ward', 'lga']])\n",
        "dhs_ward_impute['imputed_frac_poor'] = dhs_ward_impute.apply(\n",
        "    lambda x: impute_ward_with_lga(x, 'poor'), axis=1)\n",
        "dhs_ward_impute['imputed_frac_ultrapoor'] = dhs_ward_impute.apply(\n",
        "    lambda x: impute_ward_with_lga(x, 'ultrapoor'), axis=1)\n",
        "\n",
        "dhs_ward_impute = dhs_ward_impute.merge(\n",
        "    dhs_lga_impute[['lga', 'imputed_frac_poor', 'imputed_frac_ultrapoor']].\n",
        "    rename({'imputed_frac_poor': 'state_frac_poor',\n",
        "            'imputed_frac_ultrapoor': 'state_frac_ultrapoor',}, axis=1),\n",
        "    on='lga')\n",
        "\n",
        "def replace_with_state(df, colname):\n",
        "    df.loc[df['imputed_%s' % colname].isna(), 'imputed_%s' % colname] = \\\n",
        "    df.loc[df['imputed_%s' % colname].isna(), 'state_%s' % colname]\n",
        "\n",
        "replace_with_state(dhs_ward_impute, 'frac_poor')\n",
        "replace_with_state(dhs_ward_impute, 'frac_ultrapoor')\n",
        "\n",
        "print(round(pearsonr(dhs_ward_impute['imputed_frac_poor'],\n",
        "                     dhs_ward_impute['frac_poor'])[0], 3))\n",
        "print(round(pearsonr(dhs_ward_impute['imputed_frac_ultrapoor'],\n",
        "                     dhs_ward_impute['frac_ultrapoor'])[0], 3))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vSF8ux4DeYN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nXp_NXy3q0ZL"
      },
      "outputs": [],
      "source": [
        "#@title Bootstrap helpers, frac poor\n",
        "def get_random_roc(groupby_col, pop_df, n_to_replace, random_df, nlss_pls,\n",
        "                   target):\n",
        "    target_colname = 'target_frac_%s' % target\n",
        "\n",
        "    replace = random_df.sample(n_to_replace)[groupby_col].to_list()\n",
        "    random_df[target_colname] = random_df['frac_%s' % target]\n",
        "\n",
        "    random_df.loc[random_df[groupby_col].isin(replace), target_colname] = \\\n",
        "        random_df.loc[random_df[groupby_col].isin(replace),\n",
        "                      'imputed_frac_%s' % target]    \n",
        "    dhs_pls_reg = nlss_pls.merge(random_df[[groupby_col, target_colname]])\\\n",
        "                          .sort_values(by=target_colname, ascending=False)\n",
        "    return get_inc_ex_frac(dhs_pls_reg, target)\n",
        "\n",
        "def get_auc(df, col1, col2):\n",
        "    return auc(df.sort_values(col1)[col1], df.sort_values(col1)[col2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jDF7HStn9zkh"
      },
      "outputs": [],
      "source": [
        "#@title Bootstrap LGAs w imputation, DHS\n",
        "np.random.seed(123)\n",
        "\n",
        "n_to_replace = round((1 - (len(dhs_lga_impute) / len(lgas))) * len(dhs_pls_lga))\n",
        "dhs_lga_impute = dhs_lga_impute[dhs_lga_impute['lga'].isin(roc_lgas['lga'])]\n",
        "\n",
        "lga_output = []   \n",
        "b = 1000\n",
        "for i in range(b):\n",
        "    pl_cols = ['lga', 'asset_poor_w', 'asset_ultrapoor_w', 'pop']\n",
        "\n",
        "    lga_pls_poor_i = get_random_roc('lga', lgas, n_to_replace, dhs_lga_impute,\n",
        "                                    nlss_pls_lga[pl_cols], 'poor')\n",
        "    lga_pls_ultrapoor_i = get_random_roc('lga', lgas, n_to_replace, dhs_lga_impute,\n",
        "                                        nlss_pls_lga[pl_cols], 'ultrapoor')\n",
        "    lga_pls_i = lga_pls_poor_i.merge(\n",
        "        lga_pls_ultrapoor_i[['lga', 'asset_ultrapoor_inc', 'asset_nonultrapoor_inc']])\n",
        "\n",
        "    lga_output += [(get_auc(lga_pls_i, 'asset_nonpoor_inc', 'asset_poor_inc'),\n",
        "                    get_auc(lga_pls_i, 'asset_nonultrapoor_inc', 'asset_ultrapoor_inc'),\n",
        "                    lga_pls_i)]\n",
        "\n",
        "noisy_dhs_lga_poor = sorted(lga_output, key=lambda x: x[0])[int(b / 2) - 1][2]\n",
        "noisy_dhs_lga_ultrapoor = sorted(lga_output, key=lambda x: x[1])[int(b / 2) - 1][2]\n",
        "\n",
        "ultrapoor_cols = ['asset_nonultrapoor_inc', 'asset_ultrapoor_inc']\n",
        "noisy_dhs_lga = noisy_dhs_lga_poor.drop(ultrapoor_cols, axis=1)\\\n",
        "    .merge(noisy_dhs_lga_ultrapoor[ultrapoor_cols + ['lga']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hIDH9K6Nbdqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e60c78cd-0ec5-4fcd-9a97-af8093a1617f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400 464\n"
          ]
        }
      ],
      "source": [
        "#@title Bootstrap wards w imputation, DHS\n",
        "np.random.seed(123)\n",
        "\n",
        "n_to_replace = round((1 - (len(dhs_ward) / len(wards))) * len(dhs_pls_ward))\n",
        "dhs_ward_impute = dhs_ward_impute[dhs_ward_impute['ward'].isin(roc_wards['ward'])]\n",
        "print(n_to_replace, len(dhs_ward_impute))\n",
        "\n",
        "ward_output = []\n",
        "for i in range(b):\n",
        "    pl_cols = ['ward', 'asset_poor_w', 'asset_ultrapoor_w', 'pop']\n",
        "\n",
        "    ward_pls_poor_i = get_random_roc('ward', wards, n_to_replace, dhs_ward_impute,\n",
        "                                    nlss_pls_ward[pl_cols], 'poor')\n",
        "    ward_pls_ultrapoor_i = get_random_roc('ward', wards, n_to_replace, dhs_ward_impute,\n",
        "                                        nlss_pls_ward[pl_cols], 'ultrapoor')\n",
        "    ward_pls_i = ward_pls_poor_i.merge(\n",
        "        ward_pls_ultrapoor_i[['ward', 'asset_ultrapoor_inc', 'asset_nonultrapoor_inc']])\n",
        "\n",
        "    ward_output += [(get_auc(ward_pls_i, 'asset_nonpoor_inc', 'asset_poor_inc'),\n",
        "                    get_auc(ward_pls_i, 'asset_nonultrapoor_inc', 'asset_ultrapoor_inc'),\n",
        "                    ward_pls_i)]\n",
        "\n",
        "noisy_dhs_ward_poor = sorted(ward_output, key=lambda x: x[0])[int(b / 2) - 1][2]\n",
        "noisy_dhs_ward_ultrapoor = sorted(ward_output, key=lambda x: x[1])[int(b / 2) - 1][2]\n",
        "\n",
        "ultrapoor_cols = ['asset_nonultrapoor_inc', 'asset_ultrapoor_inc']\n",
        "noisy_dhs_ward = noisy_dhs_ward_poor.drop(ultrapoor_cols, axis=1)\\\n",
        "    .merge(noisy_dhs_ward_ultrapoor[ultrapoor_cols + ['ward']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "n-tHokbAbOuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "546cf2c7-1023-414f-d7e9-32018e3e29ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLSS\n",
            "poor 0.789 very poor 0.769\n",
            "poor 0.896 very poor 0.894\n",
            "poor 0.95 very poor 0.964\n",
            "\n",
            "Satellite\n",
            "poor 0.769 very poor 0.72\n",
            "poor 0.824 very poor 0.774\n",
            "poor 0.861 very poor 0.835\n",
            "\n",
            "DHS upper\n",
            "poor 0.775 very poor 0.735\n",
            "poor 0.812 very poor 0.713\n",
            "poor 0.861 very poor 0.72\n",
            "\n",
            "DHS lower\n",
            "poor 0.804 very poor 0.721\n",
            "poor 0.802 very poor 0.774\n"
          ]
        }
      ],
      "source": [
        "# @title Get ROC\n",
        "print('NLSS')\n",
        "get_roc(nlss_pls_state)\n",
        "get_roc(nlss_pls_lga)\n",
        "get_roc(nlss_pls_ward)\n",
        "print('\\nSatellite')\n",
        "get_roc(didl_pls_state)\n",
        "get_roc(didl_pls_lga)\n",
        "get_roc(didl_pls_ward)\n",
        "print('\\nDHS upper')\n",
        "get_roc(dhs_pls_state)\n",
        "get_roc(dhs_pls_lga)\n",
        "get_roc(dhs_pls_ward)\n",
        "print('\\nDHS lower')\n",
        "get_roc(noisy_dhs_lga)\n",
        "get_roc(noisy_dhs_ward)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fCCyZs8Azjxo"
      },
      "outputs": [],
      "source": [
        "#@title Get ward data for R\n",
        "keep_cols = ['asset_nonpoor_inc', 'asset_poor_inc',\n",
        "             'asset_ultrapoor_inc', 'asset_nonultrapoor_inc']\n",
        "r_ward_nlss = nlss_pls_ward[keep_cols]\n",
        "r_ward_didl = didl_pls_ward[keep_cols]\n",
        "r_ward_dhs = dhs_pls_ward[keep_cols]\n",
        "r_noisy_dhs_ward_poor = noisy_dhs_ward[keep_cols]\\\n",
        "    .sort_values('asset_nonpoor_inc')\n",
        "r_noisy_dhs_ward_ultrapoor = noisy_dhs_ward[keep_cols]\\\n",
        "    .sort_values('asset_nonultrapoor_inc')\n",
        "\n",
        "r_ward_nlss['type'] = 'Optimal'\n",
        "r_ward_didl['type'] = 'Satellite'\n",
        "r_ward_dhs['type'] = 'DHS'\n",
        "r_noisy_dhs_ward_poor['type'] = 'DHS 86.3% imputed'\n",
        "r_noisy_dhs_ward_ultrapoor['type'] = 'DHS 86.3% imputed'\n",
        "\n",
        "r_ward_roc_df_poor = pd.concat([r_ward_nlss, r_ward_didl, r_ward_dhs,\n",
        "                                r_noisy_dhs_ward_poor])\n",
        "# r_ward_roc_df_poor.to_csv(OUT_DIR + 'ward_roc_poor_frac.csv', index=False)\n",
        "r_ward_roc_df_ultrapoor = pd.concat([r_ward_nlss, r_ward_didl, r_ward_dhs,\n",
        "                                     r_noisy_dhs_ward_ultrapoor])\n",
        "# r_ward_roc_df_ultrapoor.to_csv(OUT_DIR + 'ward_roc_ultrapoor_frac.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RVUW0sn2xBV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9ruwd6d2xJ5"
      },
      "source": [
        "#Do median targeting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pyY9IMyW92k1"
      },
      "outputs": [],
      "source": [
        "#@title Median wealth helpers\n",
        "nlss_pls_median = nlss_pls.copy()\n",
        "nlss_pls_median['rwi'] = nlss_pls_median['nlss_rwi_w'] / nlss_pls_median['popw']\n",
        "nlss_pls_med_state = nlss_pls_median.groupby('state')\\\n",
        "    .apply(get_weighted_quantile_by_group, 'rwi', 'popw', 'state_rwi_q')\\\n",
        "    .drop('state', axis=1)\\\n",
        "    .reset_index()\\\n",
        "    .drop('level_1', axis=1)\n",
        "\n",
        "def get_weighted_quantile_by_group(df, sort_col, weight_col, out_col):\n",
        "    df = df.sort_values(sort_col)\n",
        "    df['cum_weight'] = df[weight_col].cumsum()\n",
        "    total = df[weight_col].sum()\n",
        "    dedup = df.drop_duplicates(sort_col, keep='last')\n",
        "    dedup[out_col] = dedup['cum_weight'] / total\n",
        "    return df.merge(dedup[[sort_col, out_col]], on=sort_col)\\\n",
        "             .drop('cum_weight', axis=1)\n",
        "\n",
        "def get_median_rows(df, op, med_df=nlss_pls_med_state):\n",
        "    df_state = df.groupby('state')['state_rwi_q']\\\n",
        "                 .apply(op).reset_index()\\\n",
        "                 .merge(med_df) \n",
        "    df_state['rwi'] = df_state['nlss_rwi_w'] / df_state['popw']\n",
        "    return df_state[['state', 'state_rwi_q', 'rwi']].drop_duplicates()\n",
        "\n",
        "def calc_median(x):\n",
        "    if x['lower_q'] == 0.5:\n",
        "        return x['lower_rwi']\n",
        "    lower_weight = 1 / (0.5 - x['lower_q'])\n",
        "    upper_weight = 1 / (x['upper_q'] - 0.5)\n",
        "    return ((lower_weight * x['lower_rwi'] + upper_weight * x['upper_rwi']) /\n",
        "            (lower_weight + upper_weight))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hjNxewreuwi1"
      },
      "outputs": [],
      "source": [
        "#@title Get region-level NLSS median wealth estimates\n",
        "\n",
        "nlss_pls_median = nlss_pls.copy()\n",
        "nlss_pls_median['rwi'] = nlss_pls_median['nlss_rwi_w'] / nlss_pls_median['popw']\n",
        "nlss_pls_med_state = nlss_pls_median.groupby('state')\\\n",
        "    .apply(get_weighted_quantile_by_group, 'rwi', 'popw', 'state_rwi_q')\\\n",
        "    .drop('state', axis=1)\\\n",
        "    .reset_index()\\\n",
        "    .drop('level_1', axis=1)\n",
        "\n",
        "lower_bound_pls_state = get_median_rows(\n",
        "    nlss_pls_med_state[nlss_pls_med_state['state_rwi_q'] <= 0.5],\n",
        "    lambda x: max(x))\\\n",
        "    .rename({'state_rwi_q': 'lower_q', 'rwi': 'lower_rwi'}, axis=1)\n",
        "\n",
        "upper_bound_pls_state = get_median_rows(\n",
        "    nlss_pls_med_state[nlss_pls_med_state['state_rwi_q'] >= 0.5],\n",
        "    lambda x: min(x))\\\n",
        "    .rename({'state_rwi_q': 'upper_q', 'rwi': 'upper_rwi'}, axis=1)\n",
        "\n",
        "nlss_pls_med_state = lower_bound_pls_state.merge(upper_bound_pls_state,\n",
        "                                                 on='state')\n",
        "nlss_pls_med_state['median_rwi'] = nlss_pls_med_state.apply(calc_median, axis=1)\n",
        "\n",
        "nlss_pls_med_lga = nlss_pls_median.groupby('lga')['rwi']\\\n",
        "                                  .median().reset_index()\n",
        "nlss_pls_med_ward = nlss_pls_median.groupby('ward')['rwi']\\\n",
        "                                   .median().reset_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "F51YEyi178AC"
      },
      "outputs": [],
      "source": [
        "#@title Make NLSS state-level targeting df\n",
        "nlss_pls_state = nlss_pls.groupby('state')\\\n",
        "    [['asset_poor_w', 'asset_ultrapoor_w']].sum().reset_index()\n",
        "nlss_pls_state = nlss_pls_state.merge(states)\\\n",
        "    .merge(nlss_pls_med_state[['state', 'median_rwi']])\n",
        "\n",
        "nlss_pls_state = nlss_pls_state.sort_values(by='median_rwi')\n",
        "nlss_pls_state['cum_pop'] = nlss_pls_state['pop'].cumsum()\n",
        "\n",
        "nlss_pls_state['asset_poor_inc'] = nlss_pls_state['asset_poor_w'].cumsum() \\\n",
        "    / total_poor\n",
        "nlss_pls_state['asset_ultrapoor_inc'] = nlss_pls_state['asset_ultrapoor_w']\\\n",
        "    .cumsum() / total_ultrapoor\n",
        "nlss_pls_state['asset_nonpoor_inc'] = (nlss_pls_state['cum_pop'] -\n",
        "    nlss_pls_state['asset_poor_w'].cumsum()) \\\n",
        "    / (states['pop'].sum() * (1 - poor_thresh))\n",
        "nlss_pls_state['asset_nonultrapoor_inc'] = (nlss_pls_state['cum_pop'] -\n",
        "    nlss_pls_state['asset_ultrapoor_w'].cumsum()) \\\n",
        "    / (states['pop'].sum() * (1 - ultrapoor_thresh))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1tOBbhYd774n"
      },
      "outputs": [],
      "source": [
        "#@title LGA/ward poverty line df helper\n",
        "def get_region_pl_df_uw(pop_df, groupby_col, target_df, pls_df=nlss_pls):\n",
        "    nlss_pls_means = pls_df.groupby(groupby_col)[['asset_poor', 'asset_ultrapoor']]\\\n",
        "                           .mean()\\\n",
        "                           .reset_index()\\\n",
        "                           .merge(target_df)\\\n",
        "                           .merge(pop_df[[groupby_col, 'pop']])\n",
        "    return augment_region_pl_df_uw(nlss_pls_means.sort_values(by='rwi'))\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tZTjgI6b85yW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "697f3bae-7e33-4bac-a832-78a054011085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asset poor frac, lgas: 0.408\n",
            "Asset very poor frac, lgas: 0.0912\n",
            "Asset poor frac, wards: 0.29\n",
            "Asset very poor frac, wards: 0.0662\n"
          ]
        }
      ],
      "source": [
        "#@title NLSS LGA and ward level targeting DFs\n",
        "# NLSS poverty lines, LGA\n",
        "nlss_pls_lga = get_region_pl_df_uw(roc_lgas, 'lga', nlss_pls_med_lga)\n",
        "print('Asset poor frac, lgas:', round(nlss_pls_lga['asset_poor_w'].sum() /\n",
        "                                nlss_pls_lga['pop'].sum(), 3))\n",
        "print('Asset very poor frac, lgas:', round(nlss_pls_lga['asset_ultrapoor_w'].sum() /\n",
        "                                     nlss_pls_lga['pop'].sum(), 4))\n",
        "\n",
        "# NLSS poverty lines, ward\n",
        "nlss_pls_ward = get_region_pl_df_uw(roc_wards, 'ward', nlss_pls_med_ward)\n",
        "print('Asset poor frac, wards:', round(nlss_pls_ward['asset_poor_w'].sum() /\n",
        "                                nlss_pls_ward['pop'].sum(), 3))\n",
        "print('Asset very poor frac, wards:', round(nlss_pls_ward['asset_ultrapoor_w'].sum() /\n",
        "                                     nlss_pls_ward['pop'].sum(), 4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTPlo2jQQ_Tv"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "k5zw3cNVQ0te"
      },
      "outputs": [],
      "source": [
        "#@title DIDL and DHS shared median helpers\n",
        "def get_median_rows_didl(df, op, groupby, q_col, q_df, rwi_col):\n",
        "    df_med = df.groupby(groupby)[q_col].apply(op).reset_index().merge(q_df) \n",
        "    return df_med[[groupby, q_col, rwi_col]].drop_duplicates()\n",
        "\n",
        "def get_medians_from_quantiles(q_df, groupby_col, q_col, rwi_col):\n",
        "    lower_bound = get_median_rows_didl(q_df[q_df[q_col] <= 0.5],\n",
        "        lambda x: max(x), groupby_col, q_col, q_df, rwi_col)\\\n",
        "        .rename({q_col: 'lower_q', rwi_col: 'lower_rwi'}, axis=1)\n",
        "\n",
        "    upper_bound = get_median_rows_didl(q_df[q_df[q_col] >= 0.5],\n",
        "        lambda x: min(x), groupby_col, q_col, q_df, rwi_col)\\\n",
        "        .rename({q_col: 'upper_q', rwi_col: 'upper_rwi'}, axis=1)\n",
        "\n",
        "    medians = lower_bound.merge(upper_bound, on=groupby_col)\n",
        "    medians['median_rwi'] = medians.apply(calc_median, axis=1)\n",
        "    return medians\n",
        "\n",
        "def get_inc_ex(pls_reg):\n",
        "    pls_reg['cum_pop'] = pls_reg['pop'].cumsum()\n",
        "\n",
        "    pls_reg['asset_poor_inc'] = pls_reg['asset_poor_w'].cumsum() \\\n",
        "                                / pls_reg['asset_poor_w'].sum()\n",
        "    pls_reg['asset_ultrapoor_inc'] = pls_reg['asset_ultrapoor_w'].cumsum() \\\n",
        "                                     / pls_reg['asset_ultrapoor_w'].sum()\n",
        "    pls_reg['asset_nonpoor_inc'] = (pls_reg['cum_pop'] - pls_reg['asset_poor_w'].cumsum()) \\\n",
        "                                    / (pls_reg['pop'].sum() - pls_reg['asset_poor_w'].sum())\n",
        "    pls_reg['asset_nonultrapoor_inc'] = (pls_reg['cum_pop'] -\n",
        "                                         pls_reg['asset_ultrapoor_w'].cumsum()) \\\n",
        "                                         / (pls_reg['pop'].sum() -\n",
        "                                         pls_reg['asset_ultrapoor_w'].sum())\n",
        "    return pls_reg\n",
        "\n",
        "def get_didl_dhs_pl_df(groupby_col, medians_reg, nlss_pls_reg, sort_col):\n",
        "    pls_reg = nlss_pls_reg.merge(medians_reg[[groupby_col, sort_col]])\\\n",
        "                               .sort_values(by=sort_col)\n",
        "    return get_inc_ex(pls_reg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zzeaK-_jQ_QG"
      },
      "outputs": [],
      "source": [
        "#@title Get DIDL overlap with regions dataframe\n",
        "\n",
        "def calc_overlaps(df, region):\n",
        "    edge_tiles = df[df.duplicated(subset=['x', 'y'], keep=False)]\n",
        "    center_tiles = df.drop_duplicates(subset=['x', 'y'], keep=False)\n",
        "\n",
        "    def frac_intersecting(x):\n",
        "        return (x['geometry'].intersection(x[region + '_geom']).area /\n",
        "                x['geometry'].area)\n",
        "\n",
        "    edge_tiles['overlap_frac'] = edge_tiles.apply(frac_intersecting, axis=1)\n",
        "    center_tiles['overlap_frac'] = 1\n",
        "    return pd.concat([edge_tiles, center_tiles])\n",
        "\n",
        "def get_overlaps_df(didl_orig_all, region_df, region):\n",
        "    didl_reg = gpd.sjoin(didl_orig_all, region_df[[region, 'geometry']],\n",
        "                         op='intersects')\\\n",
        "               .merge(region_df[[region, 'geometry']]\n",
        "               .rename({'geometry': region + '_geom'}, axis=1))\\\n",
        "               .drop(['index_right'], axis=1)\n",
        "    overlaps = calc_overlaps(didl_reg, region)\n",
        "    overlaps['region_pop'] = overlaps['pop'] * overlaps['overlap_frac']\n",
        "    return overlaps\n",
        "\n",
        "# ward_overlaps = get_overlaps_df(didl_orig_all, wards, 'ward')\n",
        "# lga_overlaps = get_overlaps_df(didl_orig_all, lgas, 'lga')\n",
        "# state_overlaps = get_overlaps_df(didl_orig_all, states, 'state')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QH9FyKULKCf_"
      },
      "outputs": [],
      "source": [
        "#@title Get DIDL ward/LGA median rwi\n",
        "\n",
        "t0 = time.time()\n",
        "median_path = NOT_INC_DATA_PATH + 'estimates/'\n",
        "\n",
        "# didl_q_ward = ward_overlaps.groupby('ward').apply(\n",
        "#     get_weighted_quantile_by_group, 'estimated_rwi', 'region_pop', 'rwi_q')\n",
        "# didl_pls_med_ward = get_medians_from_quantiles(\n",
        "#     didl_q_ward.drop(['ward'], axis=1).reset_index(),\n",
        "#     'ward', 'rwi_q', 'estimated_rwi')\n",
        "didl_pls_med_ward = pd.read_csv(median_path + 'didl_ward_median_rwi.csv')\n",
        "\n",
        "# didl_q_lga = lga_overlaps.groupby('lga').apply(\n",
        "#     get_weighted_quantile_by_group, 'estimated_rwi', 'region_pop', 'rwi_q')\n",
        "# didl_pls_med_lga = get_medians_from_quantiles(\n",
        "#     didl_q_lga.drop(['lga'], axis=1).reset_index(),\n",
        "#     'lga', 'rwi_q', 'estimated_rwi')\n",
        "didl_pls_med_lga = pd.read_csv(median_path + 'didl_lga_median_rwi.csv')\n",
        "\n",
        "# didl_q_state = state_overlaps.groupby('state').apply(\n",
        "#     get_weighted_quantile_by_group, 'estimated_rwi', 'region_pop', 'rwi_q')\n",
        "# didl_pls_med_state = get_medians_from_quantiles(\n",
        "#     didl_q_state.drop(['state'], axis=1).reset_index(),\n",
        "#     'state', 'rwi_q', 'estimated_rwi')\n",
        "didl_pls_med_state = pd.read_csv(median_path + 'didl_state_median_rwi.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bxB1o1EE4e7_"
      },
      "outputs": [],
      "source": [
        "#@title Get DIDL data for ROC plot\n",
        "\n",
        "didl_pls_state = get_didl_dhs_pl_df('state', didl_pls_med_state,\n",
        "                                nlss_pls_state.drop('median_rwi', axis=1),\n",
        "                                'median_rwi')\n",
        "didl_pls_lga = get_didl_dhs_pl_df('lga', didl_pls_med_lga,\n",
        "                              nlss_pls_lga, 'median_rwi')\n",
        "didl_pls_ward = get_didl_dhs_pl_df('ward', didl_pls_med_ward,\n",
        "                               nlss_pls_ward, 'median_rwi')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ctK_cI5ZJiew"
      },
      "outputs": [],
      "source": [
        "#@title Get DHS data for ROC plot\n",
        "\n",
        "# DHS state\n",
        "dhs_q_state = dhs_eval.groupby('geo_state').apply(\n",
        "    get_weighted_quantile_by_group, 'dhs_rwi', 'weight', 'rwi_q')\\\n",
        "    .drop('geo_state', axis=1).reset_index()\\\n",
        "    .rename({'geo_state': 'state'}, axis=1)\n",
        "dhs_pls_med_state = get_medians_from_quantiles(dhs_q_state, 'state',\n",
        "                                               'rwi_q', 'dhs_rwi')\n",
        "dhs_pls_state = get_didl_dhs_pl_df('state', dhs_pls_med_state,\n",
        "    nlss_pls_state.drop('median_rwi', axis=1), 'median_rwi')\n",
        "\n",
        "# DHS LGA\n",
        "dhs_q_lga = dhs_eval.groupby('lga').apply(\n",
        "    get_weighted_quantile_by_group, 'dhs_rwi', 'weight', 'rwi_q')\\\n",
        "    .drop('lga', axis=1).reset_index()\n",
        "dhs_pls_med_lga = get_medians_from_quantiles(dhs_q_lga, 'lga',\n",
        "                                             'rwi_q', 'dhs_rwi')\n",
        "dhs_pls_lga = get_didl_dhs_pl_df('lga', dhs_pls_med_lga,\n",
        "                                 nlss_pls_lga, 'median_rwi')\n",
        "\n",
        "# DHS ward\n",
        "dhs_q_ward = dhs_eval.groupby('ward').apply(\n",
        "    get_weighted_quantile_by_group, 'dhs_rwi', 'weight', 'rwi_q')\\\n",
        "    .drop('ward', axis=1).reset_index()\n",
        "dhs_pls_med_ward = get_medians_from_quantiles(dhs_q_ward, 'ward',\n",
        "                                              'rwi_q', 'dhs_rwi')\n",
        "dhs_pls_ward = get_didl_dhs_pl_df('ward', dhs_pls_med_ward,\n",
        "                                  nlss_pls_ward, 'median_rwi')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qL2FgK3KJep-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42a6f5fa-0f0b-49b1-9220-1ea38f288496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.687\n"
          ]
        }
      ],
      "source": [
        "#@title Make imputed DHS df -- LGAs, median\n",
        "\n",
        "def impute_dhs_median(df):\n",
        "    df = get_weighted_quantile_by_group(df, 'dhs_rwi', 'weight', 'rwi_q')\n",
        "\n",
        "    lower_q = df.loc[df['rwi_q'] <= 0.5, 'rwi_q'].max()\n",
        "    lower_rwi = df.loc[df['rwi_q'] == lower_q, 'dhs_rwi'].iloc[0]\n",
        "    upper_q = df.loc[df['rwi_q'] >= 0.5, 'rwi_q'].min()\n",
        "    upper_rwi = df.loc[df['rwi_q'] == upper_q, 'dhs_rwi'].iloc[0]\n",
        "\n",
        "    if lower_rwi == upper_rwi:\n",
        "        return lower_rwi\n",
        "    else: \n",
        "        lower_weight = 1 / (0.5 - lower_q)\n",
        "        upper_weight = 1 / (upper_q - 0.5)\n",
        "        return ((lower_weight * lower_rwi + upper_weight * upper_rwi) /\n",
        "                (lower_weight + upper_weight))\n",
        "\n",
        "def impute_lga_med_with_state(row):\n",
        "    drop_lga_df = dhs_eval.loc[(dhs_eval['lga'] != row['lga']) &\n",
        "                            (dhs_eval['geo_state'] == row['state'])]\n",
        "    return impute_dhs_median(drop_lga_df)\n",
        "\n",
        "dhs_lga_impute = dhs_pls_med_lga.merge(lgas[['lga', 'state']])\n",
        "dhs_lga_impute['imputed_median'] = dhs_lga_impute.apply(\n",
        "    impute_lga_med_with_state, axis=1)\n",
        "\n",
        "print(round(pearsonr(dhs_lga_impute['median_rwi'],\n",
        "                     dhs_lga_impute['imputed_median'])[0], 3))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "O272hlsSMZkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ea52d2b-b89f-428b-e1b3-0e36fdc90c2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.685\n"
          ]
        }
      ],
      "source": [
        "# @title Make imputed DHS df -- wards, median\n",
        "t0 = time.time()\n",
        "def impute_ward_with_lga(row):\n",
        "    drop_ward_df = dhs_eval.loc[(dhs_eval['ward'] != row['ward']) &\n",
        "                                 (dhs_eval['lga'] == row['lga'])]\n",
        "    if len(drop_ward_df) == 0:\n",
        "        return None\n",
        "    return impute_dhs_median(drop_ward_df)\n",
        "\n",
        "dhs_ward_impute = dhs_pls_med_ward.merge(wards[['ward', 'lga']])\n",
        "dhs_ward_impute['imputed_median'] = dhs_ward_impute.apply(\n",
        "    impute_ward_with_lga, axis=1)\n",
        "    \n",
        "dhs_ward_impute = dhs_ward_impute.merge(\n",
        "    dhs_lga_impute[['lga', 'imputed_median']].\n",
        "    rename({'imputed_median': 'state_median'}, axis=1),\n",
        "    on='lga')\n",
        "\n",
        "def replace_with_state(df, colname):\n",
        "    df.loc[df['imputed_%s' % colname].isna(), 'imputed_%s' % colname] = \\\n",
        "    df.loc[df['imputed_%s' % colname].isna(), 'state_%s' % colname]\n",
        "\n",
        "replace_with_state(dhs_ward_impute, 'median')\n",
        "print(round(pearsonr(dhs_ward_impute['imputed_median'],\n",
        "                     dhs_ward_impute['median_rwi'])[0], 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "j8J176y9Jel5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dbc5bd2-c6d5-4787-e8fe-e1786ab26839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110 597\n"
          ]
        }
      ],
      "source": [
        "#@title Bootstrap LGAs w imputation, DHS\n",
        "np.random.seed(123)\n",
        "\n",
        "def get_random_roc(groupby_col, pop_df, n_to_replace, random_df, nlss_pls):\n",
        "    replace = random_df.sample(n_to_replace)[groupby_col].to_list()\n",
        "    random_df['rwi'] = random_df['median_rwi']\n",
        "    random_df.loc[random_df[groupby_col].isin(replace), 'rwi'] = \\\n",
        "        random_df.loc[random_df[groupby_col].isin(replace), 'imputed_median']    \n",
        "    dhs_pls_reg = nlss_pls.merge(random_df[[groupby_col, 'rwi']])\\\n",
        "                          .sort_values(by='rwi')\n",
        "    return get_inc_ex(dhs_pls_reg)\n",
        "\n",
        "def get_auc(df, col1, col2):\n",
        "    return auc(df.sort_values(col1)[col1], df.sort_values(col1)[col2])\n",
        "\n",
        "n_to_replace = round((1 - (len(dhs_lga_impute) / len(lgas))) * len(dhs_pls_lga))\n",
        "dhs_lga_impute = dhs_lga_impute[dhs_lga_impute['lga'].isin(roc_lgas['lga'])]\n",
        "print(n_to_replace, len(dhs_lga_impute))\n",
        "\n",
        "nlss_pls_cols = ['lga', 'pop', 'asset_poor_w', 'asset_ultrapoor_w',\n",
        "                 'asset_poor_inc', 'asset_ultrapoor_inc', 'asset_nonpoor_inc',\n",
        "                 'asset_nonultrapoor_inc']\n",
        "nlss_pls_impute = nlss_pls_lga[nlss_pls_cols]\n",
        "\n",
        "lga_output = []\n",
        "b = 1000\n",
        "\n",
        "for i in range(b):\n",
        "    lga_pls_i = get_random_roc('lga', lgas, n_to_replace,\n",
        "                               dhs_lga_impute, nlss_pls_impute)\n",
        "    lga_output += [(get_auc(lga_pls_i, 'asset_nonpoor_inc', 'asset_poor_inc'),\n",
        "        get_auc(lga_pls_i, 'asset_nonultrapoor_inc', 'asset_ultrapoor_inc'),\n",
        "        lga_pls_i)]\n",
        "\n",
        "noisy_dhs_lga_poor = sorted(lga_output, key=lambda x: x[0])[int(b / 2) - 1][2]\n",
        "noisy_dhs_lga_ultrapoor = sorted(lga_output, key=lambda x: x[1])[int(b / 2) - 1][2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WdWh6fiZE2q0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaa2a3c2-b840-45d7-fa52-db88321f65b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400 464\n"
          ]
        }
      ],
      "source": [
        "#@title Bootstrap wards w imputation, DHS\n",
        "np.random.seed(123)\n",
        "\n",
        "n_to_replace = round((1 - (len(dhs_ward) / len(wards))) * len(dhs_pls_ward))\n",
        "dhs_ward_impute = dhs_ward_impute[dhs_ward_impute['ward'].isin(roc_wards['ward'])]\n",
        "print(n_to_replace, len(dhs_ward_impute))\n",
        "\n",
        "nlss_pls_cols = ['ward', 'pop', 'asset_poor_w', 'asset_ultrapoor_w',\n",
        "                 'asset_poor_inc', 'asset_ultrapoor_inc', 'asset_nonpoor_inc',\n",
        "                 'asset_nonultrapoor_inc']\n",
        "nlss_pls_impute = nlss_pls_ward[nlss_pls_cols]\n",
        "\n",
        "ward_output = []\n",
        "for i in range(b):\n",
        "    ward_pls_i = get_random_roc('ward', wards, n_to_replace,\n",
        "                                dhs_ward_impute, nlss_pls_impute)\n",
        "    ward_output += [(get_auc(ward_pls_i, 'asset_nonpoor_inc', 'asset_poor_inc'),\n",
        "        get_auc(ward_pls_i, 'asset_nonultrapoor_inc', 'asset_ultrapoor_inc'),\n",
        "        ward_pls_i)]\n",
        "\n",
        "noisy_dhs_ward_poor = sorted(ward_output, key=lambda x: x[0])[int(b / 2) - 1][2]\n",
        "noisy_dhs_ward_ultrapoor = sorted(ward_output, key=lambda x: x[1])[int(b / 2) - 1][2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SJZcR1SJ85rO"
      },
      "outputs": [],
      "source": [
        "#@title Get ward data for R\n",
        "keep_cols = ['asset_nonpoor_inc', 'asset_poor_inc',\n",
        "             'asset_ultrapoor_inc', 'asset_nonultrapoor_inc']\n",
        "r_ward_nlss = nlss_pls_ward[keep_cols]\n",
        "r_ward_didl = didl_pls_ward[keep_cols]\n",
        "# r_ward_dhs = dhs_pls_ward[keep_cols]\n",
        "r_noisy_dhs_ward_poor = noisy_dhs_ward_poor[keep_cols]\\\n",
        "    .sort_values('asset_nonpoor_inc')\n",
        "r_noisy_dhs_ward_ultrapoor = noisy_dhs_ward_ultrapoor[keep_cols]\\\n",
        "    .sort_values('asset_nonultrapoor_inc')\n",
        "\n",
        "r_ward_nlss['type'] = 'Optimal'\n",
        "r_ward_didl['type'] = 'Satellite'\n",
        "# r_ward_dhs['type'] = 'DHS'\n",
        "r_noisy_dhs_ward_poor['type'] = 'DHS'\n",
        "r_noisy_dhs_ward_ultrapoor['type'] = 'DHS'\n",
        "\n",
        "r_ward_roc_df_poor = pd.concat([r_ward_nlss, r_ward_didl, #r_ward_dhs,\n",
        "                                r_noisy_dhs_ward_poor])\n",
        "# r_ward_roc_df_poor.to_csv(OUT_DIR + 'ward_roc_poor_median.csv', index=False)\n",
        "r_ward_roc_df_ultrapoor = pd.concat([r_ward_nlss, r_ward_didl, #r_ward_dhs,\n",
        "                                     r_noisy_dhs_ward_ultrapoor])\n",
        "# r_ward_roc_df_ultrapoor.to_csv(OUT_DIR + 'ward_roc_ultrapoor_median.csv', index=False)\n",
        "\n",
        "# frac_poor = pd.read_csv('drive/MyDrive/poverty_map_paper/output/figure_data/0721/ward_roc_ultrapoor_frac_old.csv')\n",
        "# frac_poor = frac_poor[frac_poor['type'] != 'DHS']\n",
        "# frac_poor.loc[frac_poor['type'] == 'DHS 86.3% imputed', 'type'] = 'DHS'\n",
        "# frac_poor.to_csv('drive/MyDrive/poverty_map_paper/output/figure_data/0721/ward_roc_ultrapoor_frac.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TFMLyLulbOhG"
      },
      "outputs": [],
      "source": [
        "#@title Get ROC\n",
        "print('NLSS')\n",
        "get_roc(nlss_pls_state)\n",
        "get_roc(nlss_pls_lga)\n",
        "get_roc(nlss_pls_ward)\n",
        "print('\\nSatellite')\n",
        "get_roc(didl_pls_state)\n",
        "get_roc(didl_pls_lga)\n",
        "get_roc(didl_pls_ward)\n",
        "print('\\nDHS upper')\n",
        "get_roc(dhs_pls_state)\n",
        "get_roc(dhs_pls_lga)\n",
        "get_roc(dhs_pls_ward)\n",
        "print('\\nDHS lower')\n",
        "get_roc(noisy_dhs_lga_poor)\n",
        "get_roc(noisy_dhs_lga_ultrapoor)\n",
        "get_roc(noisy_dhs_ward_poor)\n",
        "get_roc(noisy_dhs_ward_ultrapoor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDz_sF6ruwYP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLZMhIvj8zY_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frLCrYoC1ab8"
      },
      "source": [
        "# Propensity score parity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "cellView": "form",
        "id": "Nb_pX2yd1hHt"
      },
      "outputs": [],
      "source": [
        "#@title Get propensity score dataframe\n",
        "\"\"\"\n",
        "(1) Latitude -- hh_gps_latitude\n",
        "(2) Longitude -- hh_gps_longitude\n",
        "(3) Poverty -- nlss_hhs['nlss_rwi']\n",
        "(4) Electrification -- electricity (ignore?)\n",
        "(5) Population\n",
        "    - urban/rural status of ward\n",
        "    - pop density of ward\n",
        "\"\"\"\n",
        "\n",
        "keep_cols = ['cluster', 'hhid', 'hh_gps_latitude', 'hh_gps_longitude', 'ward']\n",
        "propensity_df = nlss_data[keep_cols].merge(nlss_hhs[['hhid', 'nlss_rwi']])\\\n",
        "                                    .merge(wards[['ward', 'wardclass', 'geometry', 'pop']])\n",
        "\n",
        "propensity_df['density'] = propensity_df.apply(lambda x: x['pop'] / x['geometry'].area, axis=1)\n",
        "# propensity_df['female_hhh'] = propensity_df['male_hhh'].apply(lambda x: 0 if x == 'yes' else 1)\n",
        "# propensity_df = propensity_df.drop('male_hhh', axis=1)\n",
        "\n",
        "# propensity_df = propensity_df.groupby('cluster').mean().reset_index()\n",
        "\n",
        "propensity_cols = ['hh_gps_latitude', 'hh_gps_longitude', 'nlss_rwi', 'density']\n",
        "for col in propensity_cols:\n",
        "    propensity_df[col + '_norm'] = standardize(propensity_df[col])\n",
        "norm_cols = [x + '_norm' for x in propensity_cols]\n",
        "\n",
        "propensity_df = propensity_df[propensity_df['ward'].isin(nlss_pls_ward['ward'])]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "cellView": "form",
        "id": "ntD9WHA2Wwp7"
      },
      "outputs": [],
      "source": [
        "#@title Get demographic group dataframes\n",
        "# Helper to get dummy cols by group type\n",
        "def get_group_cols(col_df, in_colname, out_colnames, lambdas):\n",
        "    p = propensity_df.merge(col_df[['hhid', in_colname]])\n",
        "    for i in range(len(out_colnames)):\n",
        "        p[out_colnames[i]] = p[in_colname].apply(lambdas[i])\n",
        "    p.drop(in_colname, axis=1)\n",
        "    return p\n",
        "\n",
        "# Read in religion/language data\n",
        "religion = pd.read_stata(NOT_INC_DATA_PATH + 'nlss/sect1_roster.dta')\n",
        "religion = religion.loc[religion['s01q03'] == '1. HEAD', ['hhid', 's01q11']]\\\n",
        "                   .rename({'s01q11': 'religion'}, axis=1)\n",
        "lang = pd.read_stata(NOT_INC_DATA_PATH + 'nlss/sect_result.dta')[['hhid', 'Lang_Resp']]\\\n",
        "       .rename({'Lang_Resp': 'language'}, axis=1)\n",
        "\n",
        "# Get gender df\n",
        "gender_out = ['male', 'female']\n",
        "gender_lambdas = [lambda x: 0 if x == 'no' else 1,\n",
        "                  lambda x: 0 if x == 'yes' else 1]\n",
        "gender_df = get_group_cols(nlss_data, 'male_hhh', gender_out, gender_lambdas)\n",
        "\n",
        "# Get age df\n",
        "age_out = ['lt_30', '30_45', '45_60', 'gte_60']\n",
        "age_lambdas = [lambda x: 1 if x < 30 else 0,\n",
        "               lambda x: 1 if x >= 30 and x < 45 else 0,\n",
        "               lambda x: 1 if x >= 45 and x < 60 else 0,\n",
        "               lambda x: 1 if x >= 60 else 0]\n",
        "age_df = get_group_cols(nlss_data, 'age_hhh', age_out, age_lambdas)\n",
        "\n",
        "# Get religion df\n",
        "relig_out = ['christian', 'islam', 'traditional', 'other']\n",
        "relig_lambdas = [lambda x: 1 if x == '1. CHRISTIAN' else 0,\n",
        "                 lambda x: 1 if x == '2. ISLAM' else 0,\n",
        "                 lambda x: 1 if x == '3. TRADITIONAL' else 0,\n",
        "                 lambda x: 1 if x == '4. OTHER' else 0]\n",
        "relig_df = get_group_cols(religion, 'religion', relig_out, relig_lambdas)\n",
        "\n",
        "# Get ethnic group parity data\n",
        "lang_out = ['english', 'hausa', 'yoruba', 'igbo', 'other']\n",
        "lang_lambdas = [lambda x: 1 if x == '1. ENGLISH' else 0,\n",
        "                lambda x: 1 if x == '2. HAUSA' else 0,\n",
        "                lambda x: 1 if x == '3. YORUBA' else 0,\n",
        "                lambda x: 1 if x == '4. IGBO' else 0,\n",
        "                lambda x: 1 if x == '5. OTHER SPECIFY' else 0]\n",
        "lang_df = get_group_cols(lang.dropna(), 'language', lang_out, lang_lambdas) # one missing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "xw9aBJiYf1_T"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "cellView": "form",
        "id": "-BQc6YTjd9GL"
      },
      "outputs": [],
      "source": [
        "#@title Counterfactual helpers\n",
        "def add_pls(df):\n",
        "    return df[['hhid', 'ward', 'cf_hhid', 'cf_ward']]\\\n",
        "        .merge(nlss_pls[['hhid', 'nlss_rwi_q']])\\\n",
        "        .rename({'nlss_rwi_q': 'rwi_q'}, axis=1)\\\n",
        "        .merge(nlss_pls[['hhid', 'nlss_rwi_q']],\n",
        "            left_on='cf_hhid', right_on='hhid', suffixes=('', '_x'))\\\n",
        "        .drop(['hhid_x'], axis=1)\\\n",
        "        .rename({'nlss_rwi_q': 'cf_rwi_q'}, axis=1)\n",
        "\n",
        "def add_targeting_data(df, target_df, suffix):\n",
        "    df = df.merge(target_df[['ward', 'cum_pop']])\\\n",
        "           .rename({'cum_pop': 'target_q_' + suffix}, axis=1)\\\n",
        "           .merge(target_df[['ward', 'cum_pop']], left_on='cf_ward', right_on='ward',\n",
        "                  suffixes=('', '_x'))\\\n",
        "           .drop('ward_x', axis=1)\\\n",
        "           .rename({'cum_pop': 'cf_target_q_' + suffix}, axis=1)\n",
        "    df['target_q_' + suffix] /= target_df['cum_pop'].max()\n",
        "    df['cf_target_q_' + suffix] /= target_df['cum_pop'].max()\n",
        "    return df\n",
        "\n",
        "def get_counterfactuals(df, get_cf_for):\n",
        "    needs_cf = df[df[get_cf_for] == 1]\n",
        "    cf_pool = df[df[get_cf_for] == 0]\n",
        "\n",
        "    nn = NearestNeighbors(n_neighbors=1, metric='euclidean').fit(cf_pool[norm_cols])\n",
        "    neighbors = nn.kneighbors(needs_cf[norm_cols], return_distance=False)\n",
        "    needs_cf['cf_hhid'] = [cf_pool.iloc[x]['hhid'].iloc[0] for x in neighbors]\n",
        "    needs_cf['cf_ward'] = [cf_pool.iloc[x]['ward'].iloc[0] for x in neighbors]\n",
        "\n",
        "    cf = add_pls(needs_cf)\n",
        "    cf = add_targeting_data(cf, nlss_pls_ward, 'nlss')\n",
        "    cf = add_targeting_data(cf, dhs_pls_ward, 'dhs')\n",
        "    return add_targeting_data(cf, didl_pls_ward, 'didl')\n",
        "\n",
        "\"\"\"\n",
        "Mean pov % (lower = poorer) - target % (lower = sooner)\n",
        "> 0 implies hh is targeted earlier than it should be\n",
        "< 0 implies hh is targeted later than it should be\n",
        "\"\"\"\n",
        "# def get_mean_residuals(df, delta_only=False):\n",
        "#     group_resid, cf_resid, delta, pvalues = {}, {}, {}, {}\n",
        "#     for suffix in ['nlss', 'dhs', 'didl']:\n",
        "#         group_resid[suffix] = (df['rwi_q'] - df['target_q_' + suffix]).mean()\n",
        "#         cf_resid[suffix] = (df['cf_rwi_q'] - df['cf_target_q_' + suffix]).mean()\n",
        "#         delta[suffix] = group_resid[suffix] - cf_resid[suffix]\n",
        "\n",
        "#     if delta_only:\n",
        "#         return delta\n",
        "#     return group_resid, cf_resid, delta\n",
        "\n",
        "# def print_residuals(delta, group, group_df):\n",
        "#     for k in delta:\n",
        "#         print(group, k, 'N=%d' % len(group_df), round(delta[k], 3))\n",
        "\n",
        "# def get_targeting_deltas_by_group(group_df, group_cols, verbose=False):\n",
        "#     cfs = {}\n",
        "#     residuals = {}\n",
        "#     for col in group_cols:\n",
        "#         cfs[col] = get_counterfactuals(group_df, col)\n",
        "#         residuals[col] = get_mean_residuals(cfs[col])\n",
        "#         if verbose:\n",
        "#             print_residuals(residuals[col], col, cfs[col])\n",
        "#     return cfs, residuals\n",
        "\n",
        "def get_mean_residuals(df, colname):\n",
        "    data = {'group': [], 'target_type': [], 'residual_type': [], 'residual': [], 'p': []}\n",
        "    for suffix in ['nlss', 'dhs', 'didl']:\n",
        "        data['group'] += [colname] * 3\n",
        "        data['target_type'] += [suffix] * 3\n",
        "        data['residual_type'] += ['group', 'counterfactual', 'delta']\n",
        "\n",
        "        group_resid = df['rwi_q'] - df['target_q_' + suffix]\n",
        "        cf_resid = df['cf_rwi_q'] - df['cf_target_q_' + suffix]\n",
        "\n",
        "        data['residual'] += [group_resid.mean(), cf_resid.mean(), (group_resid - cf_resid).mean()]\n",
        "        data['p'] += [ttest_1samp(group_resid, popmean=0).pvalue,\n",
        "                    ttest_1samp(cf_resid, popmean=0).pvalue,\n",
        "                    ttest_ind(group_resid, cf_resid).pvalue]\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def get_targeting_deltas_by_group(group_df, group_cols):\n",
        "    cfs = {}\n",
        "    residuals = []\n",
        "    for col in group_cols:\n",
        "        cfs[col] = get_counterfactuals(group_df, col)\n",
        "        residuals.append(get_mean_residuals(cfs[col], col))\n",
        "\n",
        "    return cfs, pd.concat(residuals)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5l5B8eT_7q-",
        "outputId": "055f1aae-f8d1-4f31-faad-84eb434541de",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3724: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ],
      "source": [
        "#@title Get barchart data\n",
        "gender_cfs, gender_residuals = get_targeting_deltas_by_group(gender_df, gender_out)\n",
        "age_cfs, age_residuals = get_targeting_deltas_by_group(age_df, age_out)\n",
        "relig_cfs, relig_residuals = get_targeting_deltas_by_group(relig_df, relig_out)\n",
        "lang_cfs, lang_residuals = get_targeting_deltas_by_group(lang_df, lang_out)\n",
        "\n",
        "all_residuals = pd.concat([gender_residuals, age_residuals, relig_residuals, lang_residuals])\n",
        "\n",
        "all_deltas = all_residuals[all_residuals['residual_type'] == 'delta'].dropna()\n",
        "all_deltas[all_deltas['p'] < 0.05]\n",
        "\n",
        "cf_barchart_data = all_deltas.rename({'group': 'var',\n",
        "                                      'target_type': 'sort',\n",
        "                                      'residual': 'under_over'}, axis=1)\\\n",
        "                             .drop('residual_type', axis=1)\n",
        "\n",
        "# cf_barchart_data.to_csv(OUT_DIR + 'counterfactual_parity.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "sIere0ZqnK4s"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZeSSsFPnURl"
      },
      "source": [
        "#Main parity results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Needs to be run using data from mean targeting"
      ],
      "metadata": {
        "id": "l9qWMZs8Zq1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cdG31QXIZShk"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "kCvSopzTEa44",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Parity helpers\n",
        "poor_cols = ['nonpoor', 'poor', 'ultrapoor']\n",
        "\n",
        "def get_hh_groups(group_col, group_names, group_lambdas, hh_data):\n",
        "    hh_groups = hh_data[['ward', 'lga', 'state', 'poor', 'ultrapoor', group_col]]\n",
        "    for i in range(len(group_names)):\n",
        "        hh_groups[group_names[i]] = hh_groups[group_col].apply(group_lambdas[i])\n",
        "\n",
        "    hh_groups['nonpoor'] = hh_groups['poor'].apply(lambda x: 0 if x == 1 else 1)\n",
        "    num_poor_cols = []\n",
        "\n",
        "    for pc in poor_cols:\n",
        "        for c in group_names:\n",
        "            colname = '_'.join([pc, c])\n",
        "            hh_groups[colname] = hh_groups[pc] * hh_groups[c]\n",
        "            num_poor_cols.append(colname)\n",
        "    \n",
        "    return num_poor_cols, hh_groups\n",
        "\n",
        "def choose_pls_df(region):\n",
        "    assert region in set(['ward', 'lga'])\n",
        "    if region == 'ward':\n",
        "        return nlss_pls_ward[['ward', 'pop', 'nlss_rwi']]\n",
        "    if region == 'lga':\n",
        "        return nlss_pls_lga[['lga', 'pop', 'nlss_rwi']]\n",
        "    \n",
        "def get_region_groups(group_names, num_poor_cols, hh_groups, region, sample=False):\n",
        "    pls_df = choose_pls_df(region)\n",
        "    groups = hh_groups.groupby(region)\\\n",
        "                        [num_poor_cols + group_names + poor_cols]\\\n",
        "                        .sum().reset_index()\\\n",
        "                        .merge(pls_df)\\\n",
        "                        .sort_values('nlss_rwi')\n",
        "    if sample:\n",
        "        groups = groups.sample(frac=1, replace=True)\n",
        "    groups['sample_size'] = groups[group_names].sum(axis=1)\n",
        "    reweight = groups['pop'] / groups['sample_size']\n",
        "    for col in group_names:\n",
        "        groups[col] *= reweight\n",
        "    return groups\n",
        "\n",
        "def choose_dhs_df(region):\n",
        "    assert region in set(['ward', 'lga'])\n",
        "    if region == 'ward':\n",
        "        return noisy_dhs_ward_poor[['ward', 'rwi']]\n",
        "    if region == 'lga':\n",
        "        return noisy_dhs_lga_poor[['lga', 'rwi']]\n",
        "\n",
        "def choose_didl_df(region):\n",
        "    assert region in set(['ward', 'lga'])\n",
        "    if region == 'ward':\n",
        "        return didl_orig_ward[['ward', 'didl_orig_rwi']]\n",
        "    if region == 'lga':\n",
        "        return didl_orig_lga[['lga', 'didl_orig_rwi']]\n",
        "\n",
        "def get_plot_df(groups, group_names, region):\n",
        "    dhs_rwi_df = choose_dhs_df(region).rename({'rwi': 'dhs_rwi'}, axis=1)\n",
        "    target_df = groups[[region, 'pop', 'nlss_rwi'] + group_names]\\\n",
        "        .merge(dhs_rwi_df)\\\n",
        "        .merge(choose_didl_df(region))\n",
        "\n",
        "    plot_df = pd.DataFrame()\n",
        "\n",
        "    for rwi_col in ['nlss_rwi', 'didl_orig_rwi', 'dhs_rwi']:\n",
        "        rwi_str = rwi_col.split('_')[0]\n",
        "        target_df = target_df.sort_values(rwi_col)\n",
        "        plot_df['frac_pop_' + rwi_str] = target_df['pop'].cumsum() / \\\n",
        "            target_df['pop'].sum()\n",
        "        for group_col in group_names:\n",
        "            plot_colname = 'frac_%s_%s' % (group_col, rwi_str)\n",
        "            plot_df[plot_colname] = target_df[group_col].cumsum() / \\\n",
        "                target_df['pop'].cumsum()\n",
        "\n",
        "    return plot_df\n",
        "\n",
        "def get_frac_poor_by_group(groups, group_names):\n",
        "    reweight = groups['pop'] / groups['sample_size']\n",
        "    total_poor = (groups['poor'] * reweight).sum()\n",
        "\n",
        "    frac_poor_in_group = {}\n",
        "    for i in range(len(group_names)):\n",
        "        group = group_names[i]\n",
        "        frac_poor_in_group[group] = \\\n",
        "            (groups['poor_' + group] * reweight).sum() / total_poor\n",
        "    \n",
        "    return frac_poor_in_group\n",
        "\n",
        "def get_parity_data(group_col, group_names, group_lambdas, hh_data=nlss_data,\n",
        "                    region='ward', sample=False):\n",
        "    num_poor_cols, hh_groups = \\\n",
        "        get_hh_groups(group_col, group_names, group_lambdas, hh_data)\n",
        "    region_groups = get_region_groups(group_names, num_poor_cols, hh_groups, region, sample)\n",
        "    plot_df = get_plot_df(region_groups, group_names, region)\n",
        "    frac_poor_by_group = get_frac_poor_by_group(region_groups, group_names)\n",
        "    for group in frac_poor_by_group:\n",
        "        plot_df[group + '_poor'] = frac_poor_by_group[group]\n",
        "\n",
        "    return plot_df\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "p7aXgKdtEAOh",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Get parity data\n",
        "# Get religion and ethnic group household data\n",
        "religion = pd.read_stata(NOT_INC_DATA_PATH + 'nlss/sect1_roster.dta')\n",
        "religion = religion.loc[religion['s01q03'] == '1. HEAD', ['hhid', 's01q11']]\\\n",
        "                   .rename({'s01q11': 'religion'}, axis=1)\n",
        "lang = pd.read_stata(NOT_INC_DATA_PATH + 'nlss/sect_result.dta')[['hhid', 'Lang_Resp']]\\\n",
        "       .rename({'Lang_Resp': 'language'}, axis=1)\n",
        "nlss_aug = nlss_data.merge(religion).merge(lang)\n",
        "\n",
        "# Get gender parity data\n",
        "gender_col = 'male_hhh'\n",
        "gender_names = ['male', 'female']\n",
        "gender_lambdas = [lambda x: 0 if x == 'no' else 1,\n",
        "                 lambda x: 0 if x == 'yes' else 1]\n",
        "gender_df = get_parity_data(gender_col, gender_names, gender_lambdas)\n",
        "gender_df_lga = get_parity_data(gender_col, gender_names, gender_lambdas, region='lga')\n",
        "\n",
        "# Get age parity data\n",
        "age_col = 'age_hhh'\n",
        "age_names = ['lt_30', '30_45', '45_60', 'gte_60']\n",
        "age_lambdas = [lambda x: 1 if x < 30 else 0,\n",
        "               lambda x: 1 if x >= 30 and x < 45 else 0,\n",
        "               lambda x: 1 if x >= 45 and x < 60 else 0,\n",
        "               lambda x: 1 if x >= 60 else 0]\n",
        "age_df = get_parity_data(age_col, age_names, age_lambdas)\n",
        "age_df_lga = get_parity_data(age_col, age_names, age_lambdas, region='lga')\n",
        "\n",
        "# Get religion parity data\n",
        "relig_col = 'religion'\n",
        "relig_names = ['christian', 'islam', 'traditional', 'other']\n",
        "relig_lambdas = [lambda x: 1 if x == '1. CHRISTIAN' else 0,\n",
        "                 lambda x: 1 if x == '2. ISLAM' else 0,\n",
        "                 lambda x: 1 if x == '3. TRADITIONAL' else 0,\n",
        "                 lambda x: 1 if x == '4. OTHER' else 0]\n",
        "relig_df = get_parity_data(relig_col, relig_names, relig_lambdas, nlss_aug)\n",
        "relig_df_lga = get_parity_data(relig_col, relig_names, relig_lambdas, nlss_aug, region='lga')\n",
        "\n",
        "# Get ethnic group parity data\n",
        "lang_col = 'language'\n",
        "lang_names = ['english', 'hausa', 'yoruba', 'igbo', 'other']\n",
        "lang_lambdas = [lambda x: 1 if x == '1. ENGLISH' else 0,\n",
        "                 lambda x: 1 if x == '2. HAUSA' else 0,\n",
        "                 lambda x: 1 if x == '3. YORUBA' else 0,\n",
        "                 lambda x: 1 if x == '4. IGBO' else 0,\n",
        "                lambda x: 1 if x == '5. OTHER SPECIFY' else 0]\n",
        "lang_df = get_parity_data(lang_col, lang_names, lang_lambdas,\n",
        "                          nlss_aug[~nlss_aug['language'].isna()]) # one missing\n",
        "lang_df_lga = get_parity_data(lang_col, lang_names, lang_lambdas,\n",
        "                              nlss_aug[~nlss_aug['language'].isna()], region='lga') # one missing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PSDTLX_9qao"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "cellView": "form",
        "id": "kAXoXVbome_i"
      },
      "outputs": [],
      "source": [
        "#@title Get data for barchart\n",
        "sort = 'nlss'\n",
        "frac = 0.1\n",
        "groups = ['male', 'female']\n",
        "\n",
        "def get_barchart_data(df, groups, sort, demographic=None, frac=0.1):\n",
        "\n",
        "    def get_under_over(x):\n",
        "        actual = df[x['var'] + '_poor'].iloc[0]\n",
        "        return (x['frac'] - actual) / actual * 100\n",
        "\n",
        "    pop_col = 'frac_pop_' + sort\n",
        "    target_cols = ['frac_%s_%s' % (g, sort) for g in groups]\n",
        "\n",
        "    lower_pop = df.loc[df[pop_col] <= frac, pop_col].max()\n",
        "    upper_pop = df.loc[df[pop_col] >= frac, pop_col].min()\n",
        "    lower = df.loc[df[pop_col] == lower_pop, target_cols + [pop_col]]\n",
        "    upper = df.loc[df[pop_col] == upper_pop, target_cols + [pop_col]]\n",
        "\n",
        "    avg = pd.concat([lower, upper])\n",
        "    weights = (avg[pop_col] - frac).apply(lambda x: 1 / np.abs(x))\n",
        "    avg = avg.mul(weights, axis=0)\\\n",
        "            .sum().reset_index()\\\n",
        "            .rename({'index': 'var', 0: 'frac'}, axis=1)\n",
        "    avg = avg[avg['var'] != pop_col]\n",
        "    avg['frac'] /= weights.sum()\n",
        "    avg['var'] = avg['var'].apply(lambda x: '_'.join(x.split('_')[1:-1]))\n",
        "    avg['sort'] = sort\n",
        "    avg['under_over'] = avg.apply(get_under_over, axis=1)\n",
        "    if demographic:\n",
        "        avg['demographic'] = demographic\n",
        "    return avg\n",
        "\n",
        "bc_df = []\n",
        "gender_names = ['male', 'female']\n",
        "age_names = ['lt_30', '30_45', '45_60', 'gte_60']\n",
        "relig_names = ['christian', 'islam', 'traditional']\n",
        "lang_names = ['english', 'hausa', 'yoruba', 'igbo', 'other']\n",
        "\n",
        "for sort in ['nlss', 'dhs', 'didl']:\n",
        "    bc_df.append(get_barchart_data(gender_df, gender_names, sort, 'Gender'))\n",
        "    bc_df.append(get_barchart_data(age_df, age_names, sort, 'Age'))\n",
        "    bc_df.append(get_barchart_data(relig_df, relig_names, sort, 'Religion'))\n",
        "    bc_df.append(get_barchart_data(lang_df, lang_names, sort, 'Language'))\n",
        "\n",
        "bc_df = pd.concat(bc_df)\n",
        "\n",
        "x_df = pd.DataFrame()\n",
        "x_df['var'] = gender_names + age_names + relig_names + lang_names\n",
        "x_df['x'] = [i for i in range(len(x_df))]\n",
        "bc_df = bc_df.merge(x_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "cellView": "form",
        "id": "5JH0E4UDD_8e"
      },
      "outputs": [],
      "source": [
        "#@title Bootstrap helper\n",
        "# choose a sample of wards\n",
        "# what fraction of poor people in wards are in category?\n",
        "# what fraction of targeted people in wards are in category?\n",
        "\n",
        "def get_bootstrapped_ci(col, names, lambdas, hh_data=nlss_data,\n",
        "                    region='ward', b=1000):\n",
        "    np.random.seed(123)\n",
        "    t0 = time.time()\n",
        "\n",
        "    bs = []\n",
        "    for i in range(b):\n",
        "        df = get_parity_data(col, names, lambdas, hh_data, region, sample=True)\n",
        "        for sort in ['nlss', 'dhs', 'didl']:\n",
        "            bs.append(get_barchart_data(df, names, sort, 'Gender')) # need to vary sort\n",
        "\n",
        "    bs = pd.concat(bs)\n",
        "    bounds = []\n",
        "\n",
        "    for var in names:\n",
        "        for sort in ['nlss', 'dhs', 'didl']:\n",
        "            check = bs.loc[(bs['var'] == var) & (bs['sort'] == sort), 'under_over']\n",
        "            bounds.append([var, sort, check.quantile(0.025), check.quantile(0.975)])\n",
        "\n",
        "    bounds = pd.DataFrame(bounds, columns=['var', 'sort', 'upper', 'lower'])\n",
        "    print(names, 'complete', round(time.time() - t0), 'elapsed')\n",
        "    return bounds, bs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "cellView": "form",
        "id": "YhyINLDUzVeN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3304d1c0-8ca8-406e-d7dc-60239a1b0a2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['male', 'female'] complete 123 elapsed\n",
            "['lt_30', '30_45', '45_60', 'gte_60'] complete 157 elapsed\n",
            "['christian', 'islam', 'traditional'] complete 102 elapsed\n",
            "['english', 'hausa', 'yoruba', 'igbo', 'other'] complete 122 elapsed\n"
          ]
        }
      ],
      "source": [
        "#@title Bootstrap wards\n",
        "gender_cis, gender_bs = get_bootstrapped_ci(gender_col, gender_names, gender_lambdas)\n",
        "age_cis, age_bs = get_bootstrapped_ci(age_col, age_names, age_lambdas)\n",
        "relig_cis, relig_bs = get_bootstrapped_ci(relig_col, relig_names, relig_lambdas, nlss_aug)\n",
        "lang_cis, lang_bs = get_bootstrapped_ci(lang_col, lang_names, lang_lambdas,\n",
        "                               nlss_aug[~nlss_aug['language'].isna()])\n",
        "cis = pd.concat([gender_cis, age_cis, relig_cis, lang_cis])\n",
        "\n",
        "gender_bs.to_csv(OUT_DIR + 'gender_bs.csv', index=False)\n",
        "age_bs.to_csv(OUT_DIR + 'age_bs.csv', index=False)\n",
        "relig_bs.to_csv(OUT_DIR + 'relig_bs.csv', index=False)\n",
        "lang_bs.to_csv(OUT_DIR + 'lang_bs.csv', index=False)\n",
        "cis.to_csv(OUT_DIR + 'cis.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Zix3IYEXdNtp"
      },
      "outputs": [],
      "source": [
        "#@title Bootstrap LGAs\n",
        "# gender_cis_lga = get_bootstrapped_ci(gender_col, gender_names, gender_lambdas, region='lga')\n",
        "# age_cis_lga = get_bootstrapped_ci(age_col, age_names, age_lambdas, region='lga')\n",
        "# relig_cis_lga = get_bootstrapped_ci(relig_col, relig_names, relig_lambdas, nlss_aug, region='lga')\n",
        "# lang_cis_lga = get_bootstrapped_ci(lang_col, lang_names, lang_lambdas,\n",
        "#                                nlss_aug[~nlss_aug['language'].isna()], region='lga')\n",
        "\n",
        "# cis_lga = pd.concat([gender_cis_lga, age_cis_lga, relig_cis_lga, lang_cis_lga])\n",
        "# cis_lga.to_csv(OUT_DIR + 'cis_lga.csv', index=False)\n",
        "\n",
        "gender_cis, gender_bs = get_bootstrapped_ci(gender_col, gender_names, gender_lambdas, region='lga')\n",
        "age_cis, age_bs = get_bootstrapped_ci(age_col, age_names, age_lambdas, region='lga')\n",
        "relig_cis, relig_bs = get_bootstrapped_ci(relig_col, relig_names, relig_lambdas, nlss_aug,\n",
        "                                          region='lga')\n",
        "lang_cis, lang_bs = get_bootstrapped_ci(lang_col, lang_names, lang_lambdas,\n",
        "                                        nlss_aug[~nlss_aug['language'].isna()], region='lga')\n",
        "cis = pd.concat([gender_cis, age_cis, relig_cis, lang_cis])\n",
        "\n",
        "gender_bs.to_csv(OUT_DIR + 'gender_bs_lga.csv', index=False)\n",
        "age_bs.to_csv(OUT_DIR + 'age_bs_lga.csv', index=False)\n",
        "relig_bs.to_csv(OUT_DIR + 'relig_bs_lga.csv', index=False)\n",
        "lang_bs.to_csv(OUT_DIR + 'lang_bs_lga.csv', index=False)\n",
        "cis.to_csv(OUT_DIR + 'cis_lga.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvaJZYnkme00"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcvd4YziuU3o",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Export data to R\n",
        "# gender_df.to_csv(OUT_DIR + 'gender_parity.csv', index=False)\n",
        "# age_df.to_csv(OUT_DIR + 'age_parity.csv', index=False)\n",
        "# relig_df.to_csv(OUT_DIR + 'religion_parity.csv', index=False)\n",
        "# lang_df.to_csv(OUT_DIR + 'language_parity.csv', index=False)\n",
        "# bc_df.to_csv(OUT_DIR + 'bar_chart_parity.csv', index=False)\n",
        "\n",
        "# gender_df_lga.to_csv(OUT_DIR + 'gender_parity_lga.csv', index=False)\n",
        "# age_df_lga.to_csv(OUT_DIR + 'age_parity_lga.csv', index=False)\n",
        "# relig_df_lga.to_csv(OUT_DIR + 'religion_parity_lga.csv', index=False)\n",
        "# lang_df_lga.to_csv(OUT_DIR + 'language_parity_lga.csv', index=False)\n",
        "# bc_df.to_csv(OUT_DIR + 'bar_chart_parity_lga.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4gTnnK6merX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nJSF1fdoMN_D"
      },
      "outputs": [],
      "source": [
        "#@title R packages\n",
        "# %load_ext rpy2.ipython\n",
        "%%R\n",
        "install.packages('cowplot')\n",
        "install.packages('gridExtra')\n",
        "install.packages('Metrics')\n",
        "install.packages('showtext')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tmaJV8Xx1EPO"
      },
      "outputs": [],
      "source": [
        "#@title Setup for R plots\n",
        "%%R\n",
        "\n",
        "library(cowplot)\n",
        "# library(fixest)\n",
        "library(foreign)\n",
        "library(grid)\n",
        "library(gridExtra)\n",
        "library(Metrics)\n",
        "library(RColorBrewer)\n",
        "library(showtext)\n",
        "library(stringr)\n",
        "\n",
        "library(ggplot2)\n",
        "library(dplyr)\n",
        "library(tidyr)\n",
        "\n",
        "setwd('/content//drive/MyDrive/poverty_map_paper/')\n",
        "font_add(\"LM Roman 10\", \"fonts/Latin-Modern-Roman/lmroman10-regular.otf\")\n",
        "font_add(\"LM Roman 10 Bold\", \"fonts/Latin-Modern-Roman/lmroman10-bold.otf\")\n",
        "showtext.auto()\n",
        "\n",
        "DATA_DIR <- 'output/figure_data/0721/'\n",
        "\n",
        "pal <- brewer.pal(n=4, name='RdYlBu')\n",
        "pal3 <- pal[c(1, 2, 4)]\n",
        "target_type_pal <- c('black', 'palegreen4', 'lightblue')\n",
        "gray <- 'gray60'\n",
        "\n",
        "scatterplot_ptsz <- 1\n",
        "scatterplot_lnwt <- 0.5\n",
        "scatterplot_lncol <- pal[4]\n",
        "\n",
        "scatterplot_theme <- theme_classic() +\n",
        "  theme(text=element_text(size=28, family=\"LM Roman 10\"),\n",
        "        plot.title = element_text(hjust = 0.5, size=32),\n",
        "        legend.position = c(0.65, 0.2),\n",
        "        legend.title = element_blank(),\n",
        "        legend.text = element_text(size=14),\n",
        "        legend.margin = margin(c(0, 0, 0, 0)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tYqKL4vRcvUp"
      },
      "outputs": [],
      "source": [
        "#@title Parity plot helper\n",
        "%%R\n",
        "get_parity_plot <- function(df, group) {\n",
        "    group_col <- paste('frac_', group, sep='')\n",
        "    overall_col <- paste(group, '_poor', sep='')\n",
        "    if (grepl(\"^[[:digit:]]+\", overall_col)) {\n",
        "        overall_col <- paste('X', overall_col, sep='')\n",
        "    }\n",
        "    overall <- df[1, overall_col]\n",
        "\n",
        "    plt<- ggplot(data=df) +\n",
        "        geom_line(aes_string(x='frac_pop_nlss', y=paste(group_col, '_nlss', sep='')),\n",
        "                  size=scatterplot_lnwt, color=target_type_pal[1]) +\n",
        "        geom_line(aes_string(x='frac_pop_didl', y=paste(group_col, '_didl', sep='')),\n",
        "                  size=scatterplot_lnwt, color=target_type_pal[2]) +\n",
        "        geom_line(aes_string(x='frac_pop_dhs', y=paste(group_col, '_dhs', sep='')),\n",
        "                  size=scatterplot_lnwt, color=target_type_pal[3]) +\n",
        "        geom_abline(intercept=overall, slope=0, linetype='dashed', color=gray,\n",
        "                    size=scatterplot_lnwt) +\n",
        "        ylim(0, 1) +\n",
        "        labs(x='Fraction of Population Targeted',\n",
        "             y=paste('Fraction of Targeted Households', str_to_title(group))) +\n",
        "        scatterplot_theme\n",
        "    return(plt)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "H0EwKNHo1EEo"
      },
      "outputs": [],
      "source": [
        "#@title Get R plots\n",
        "%%R\n",
        "w = 4\n",
        "\n",
        "gender <- read.csv('output/figure_data/0721/gender_parity.csv')\n",
        "plt_f <- get_parity_plot(gender, 'female')\n",
        "plt_m <- get_parity_plot(gender, 'male')\n",
        "plt_gender <- plot_grid(plt_f, plt_m, nrow=1)\n",
        "ggsave(\"output/figures/gender.png\", units=\"in\", width=w*2, height=w, dpi=300)\n",
        "\n",
        "age <- read.csv('output/figure_data/0721/age_parity.csv')\n",
        "plt_lt_30 <- get_parity_plot(age, 'lt_30')\n",
        "plt_30_45 <- get_parity_plot(age, '30_45')\n",
        "plt_45_50 <- get_parity_plot(age, '45_60')\n",
        "plt_gte_60 <- get_parity_plot(age, 'gte_60')\n",
        "plt_age <- plot_grid(plt_lt_30, plt_30_45, plt_45_50, plt_gte_60, nrow=2)\n",
        "ggsave(\"output/figures/age.png\", units=\"in\", width=w*2, height=w*2, dpi=300)\n",
        "\n",
        "religion <- read.csv('output/figure_data/0721/religion_parity.csv')\n",
        "head(religion)\n",
        "plt_christian <- get_parity_plot(religion, 'christian');\n",
        "plt_islam <- get_parity_plot(religion, 'islam');\n",
        "plt_traditional <- get_parity_plot(religion, 'traditional');\n",
        "plt_religion <- plot_grid(plt_christian, plt_islam, plt_traditional,\n",
        "                          nrow=2)\n",
        "ggsave(\"output/figures/religion.png\", units=\"in\", width=w*2, height=w*2, dpi=300)\n",
        "\n",
        "lang <- read.csv('output/figure_data/0721/language_parity.csv')\n",
        "\n",
        "plt_english <- get_parity_plot(lang, 'english');\n",
        "plt_hausa <- get_parity_plot(lang, 'hausa');\n",
        "plt_igbo <- get_parity_plot(lang, 'igbo');\n",
        "plt_yoruba <- get_parity_plot(lang, 'yoruba');\n",
        "plt_other <- get_parity_plot(lang, 'other');\n",
        "plt_lang <- plot_grid(plt_english, plt_hausa, plt_igbo, plt_yoruba, plt_other)#\n",
        "                    #   nrow=2)\n",
        "ggsave(\"output/figures/lang.png\", units=\"in\", width=w*2, height=w*2, dpi=300)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNsj8mGlcrMF"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CzV-LmD4aJkX"
      },
      "outputs": [],
      "source": [
        "#@title Test plots\n",
        "%%R\n",
        "\n",
        "bc_data <- read.csv('output/figure_data/0721/bar_chart_parity.csv')\n",
        "\n",
        "bc <- ggplot(data=bc_data) +\n",
        "    geom_point(aes(x=x, y=under_over, color=sort), size=3) +\n",
        "    labs(x=bc_data['var']) +\n",
        "    scale_color_manual(values=c('black', 'palegreen4', 'lightblue'))#, labels=labels)\n",
        "    # scatterplot_theme\n",
        "    \n",
        "\n",
        "show(bc)\n",
        "\n",
        "# # Python\n",
        "# import imageio\n",
        "# im = imageio.imread('output/figures/lang.png')\n",
        "\n",
        "# f, ax = plt.subplots(figsize=(12, 12))\n",
        "# ax.imshow(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yhLOlinQYRtR"
      },
      "outputs": [],
      "source": [
        "#@title Test plots\n",
        "f, ax = plt.subplots()\n",
        "\n",
        "sns.lineplot(x=gender_plot_df['frac_pop_nlss'],\n",
        "             y=gender_plot_df['frac_f_nlss'],\n",
        "             color='red')\n",
        "sns.lineplot(x=gender_plot_df['frac_pop_dhs'],\n",
        "             y=gender_plot_df['frac_f_dhs'],\n",
        "             color='green')\n",
        "sns.lineplot(x=gender_plot_df['frac_pop_didl'],\n",
        "             y=gender_plot_df['frac_f_didl'],\n",
        "             color='blue')\n",
        "sns.lineplot(x=[0, 1],\n",
        "             y=[frac_of_poor_female, frac_of_poor_female])\n",
        "\n",
        "\n",
        "f, ax = plt.subplots()\n",
        "\n",
        "sns.lineplot(x=gender_plot_df['frac_pop_nlss'],\n",
        "             y=gender_plot_df['frac_m_nlss'],\n",
        "             color='red')\n",
        "sns.lineplot(x=gender_plot_df['frac_pop_dhs'],\n",
        "             y=gender_plot_df['frac_m_dhs'],\n",
        "             color='green')\n",
        "sns.lineplot(x=gender_plot_df['frac_pop_didl'],\n",
        "             y=gender_plot_df['frac_m_didl'],\n",
        "             color='blue')\n",
        "sns.lineplot(x=[0, 1],\n",
        "             y=[frac_of_poor_male, frac_of_poor_male])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6elDENQHvSGW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIrutzQ5O0dJ"
      },
      "source": [
        "# Make table 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "id": "G7hQYtTtdmvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f69d6f7-5b9d-462c-9e84-10c77107a2ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "R[write to console]: \n",
            "\n",
            "R[write to console]: \n",
            "R[write to console]: The downloaded source packages are in\n",
            "\t/tmp/Rtmph6itBe/downloaded_packages\n",
            "R[write to console]: \n",
            "R[write to console]: \n",
            "\n"
          ]
        }
      ],
      "source": [
        "%load_ext rpy2.ipython\n",
        "%R install.packages('psychometric')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "id": "KOE2aIg2gCqh"
      },
      "outputs": [],
      "source": [
        "#@title Table 1 helpers\n",
        "from rpy2.robjects.packages import importr\n",
        "psychometric = importr('psychometric')\n",
        "\n",
        "def corr(df, c1, c2):\n",
        "    r, p = pearsonr(df[c1], df[c2])\n",
        "    # if p < 0.0001:\n",
        "    #     return '%.3f (p<0.0001)' % r\n",
        "    # return '%.3f (p=%.4f)' % (r, p)\n",
        "    ci = psychometric.CIr(r=float(r), n=len(df), level = .95)\n",
        "    return '%.3f [%.3f, %.3f] (p=%.2e)' % (r, ci[0], ci[1], p)\n",
        "\n",
        "\n",
        "def print_row(dhs_df, ml_df):\n",
        "    print('n DHS: %d, n ML: %d, corr DHS: %s, corr ML: %s' %\n",
        "      (len(dhs_df),\n",
        "       len(ml_df),\n",
        "       corr(dhs_df, 'nlss_rwi', 'dhs_rwi'),\n",
        "       corr(ml_df, 'nlss_rwi', 'didl_orig_rwi')))\n",
        "\n",
        "def print_ml_only_row(ml_df):\n",
        "    print('n ML: %d, corr ML: %s' % (len(ml_df), corr(ml_df, 'nlss_rwi', 'didl_orig_rwi')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffPu0mD0d87R"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "cellView": "form",
        "id": "NjFsR_0MO4G-"
      },
      "outputs": [],
      "source": [
        "#@title Get table 1 dfs\n",
        "# State data\n",
        "state_data_table_1 = nlss_state[['state', 'nlss_rwi']].merge(\n",
        "                     didl_orig_state[['state', 'didl_orig_rwi']]).merge(\n",
        "                     dhs_state[['state', 'dhs_rwi']])\n",
        "\n",
        "# LGA data\n",
        "lga_clusters = nlss_pls.groupby(['lga'])['hhid'].nunique().reset_index()\\\n",
        "    .merge(nlss_lga)[['lga', 'hhid', 'nlss_rwi']]\n",
        "\n",
        "lgas_nlss_ml = lga_clusters.merge(didl_orig_lga[['lga', 'didl_orig_rwi']])\n",
        "lgas_all_three = lgas_nlss_ml.merge(dhs_lga[['lga', 'dhs_rwi']])\n",
        "lgas_no_dhs = lgas_nlss_ml[~lgas_nlss_ml['lga'].isin(lgas_all_three['lga'])]\n",
        "\n",
        "# Ward data\n",
        "ward_clusters = nlss_pls.groupby(['ward'])['hhid'].nunique().reset_index()\\\n",
        "    .merge(nlss_ward)[['ward', 'hhid', 'nlss_rwi']]\n",
        "\n",
        "wards_nlss_ml = ward_clusters.merge(didl_orig_ward[['ward', 'didl_orig_rwi']])\n",
        "wards_all_three = wards_nlss_ml.merge(dhs_ward[['ward', 'dhs_rwi']])\n",
        "wards_no_dhs = wards_nlss_ml[~wards_nlss_ml['ward'].isin(wards_all_three['ward'])]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eLlx2AkaO4DK"
      },
      "outputs": [],
      "source": [
        "#@title Print table 1 rows\n",
        "# Table 1 state rows\n",
        "print('All states:')\n",
        "print_row(state_data_table_1, state_data_table_1)\n",
        "print()\n",
        "\n",
        "# Table 1 LGA rows\n",
        "print('All LGAs')\n",
        "print_row(lgas_all_three, lgas_nlss_ml)\n",
        "print('LGAs with DHS data')\n",
        "print_ml_only_row(lgas_all_three)\n",
        "print('>30 ground truth households')\n",
        "print_row(lgas_all_three[lgas_all_three['hhid'] >= 30],\n",
        "          lgas_nlss_ml[lgas_nlss_ml['hhid'] >= 30])\n",
        "print('>30 ground truth households and DHS data')\n",
        "print_ml_only_row(lgas_all_three[lgas_all_three['hhid'] >= 30])\n",
        "print('LGAs with no DHS data')\n",
        "print_ml_only_row(lgas_no_dhs)\n",
        "print('>30 ground truth households and no DHS')\n",
        "print_ml_only_row(lgas_no_dhs[lgas_no_dhs['hhid'] >= 30])\n",
        "print()\n",
        "\n",
        "# Table 1 ward rows\n",
        "print('All wards')\n",
        "print_row(wards_all_three, wards_nlss_ml)\n",
        "print('Wards with DHS data')\n",
        "print_ml_only_row(wards_all_three)\n",
        "print('>20 ground truth households')\n",
        "print_row(wards_all_three[wards_all_three['hhid'] >= 20],\n",
        "          wards_nlss_ml[wards_nlss_ml['hhid'] >= 20])\n",
        "print('>20 ground truth households and DHS data')\n",
        "print_ml_only_row(wards_all_three[wards_all_three['hhid'] >= 20])\n",
        "print('Wards with no DHS data')\n",
        "print_ml_only_row(wards_no_dhs)\n",
        "print('>20 ground truth households and no DHS')\n",
        "print_ml_only_row(wards_no_dhs[wards_no_dhs['hhid'] >= 20])\n",
        "print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1MLwtafdZ28"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dArub_b6mQeQ"
      },
      "source": [
        "# Misc - tables and appendix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxZ0Z3GE5810"
      },
      "source": [
        "##Make cluster locations fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jPMX1ZrEpscd"
      },
      "outputs": [],
      "source": [
        "#@title Get NLSS df with displaced coordinates\n",
        "# DHS displacement methodology: https://dhsprogram.com/pubs/pdf/SAR8/SAR8.pdf (p. 17)\n",
        "np.random.seed(123)\n",
        "nlss_plot = nlss_data[['cluster', 'geometry']]\n",
        "nlss_plot['longitude'] = nlss_data['geometry'].x\n",
        "nlss_plot['latitude'] = nlss_data['geometry'].y\n",
        "nlss_plot = nlss_plot.groupby('cluster')[['longitude', 'latitude']].mean().reset_index()\\\n",
        "    .merge(nlss_data[['cluster', 'sector']].drop_duplicates(subset='cluster'))\n",
        "nlss_plot['disp_radius'] = \\\n",
        "    nlss_plot['sector'].apply(lambda x: 10 * 0.008 if np.random.random() <= 1/100 else\n",
        "                              2 * 0.008 if x == '1. Urban' else 5 * 0.008)\n",
        "\n",
        "def get_random(x):\n",
        "    alpha = 2 * math.pi * np.random.random()\n",
        "    r = x['disp_radius'] * math.sqrt(random.random())\n",
        "    return Point(r * math.cos(alpha) + x['longitude'],\n",
        "                 r * math.sin(alpha) + x['latitude'])\n",
        "\n",
        "nlss_plot['geometry'] = nlss_plot.apply(get_random, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yL3vvwFkO31I"
      },
      "outputs": [],
      "source": [
        "#@title Make cluster locations fig\n",
        "import matplotlib.font_manager as fm\n",
        "bold_font = fm.FontProperties(\n",
        "    fname='drive/MyDrive/poverty_map_paper/Latin-Modern-Roman/lmroman10-bold.otf')\n",
        "cmap = matplotlib.cm.get_cmap('YlGnBu')\n",
        "\n",
        "dhs_plot = dhs_eval[~dhs_eval['ward'].isna()].drop_duplicates(subset='cluster_id')\n",
        "\n",
        "sns.set_style('white')\n",
        "f, ax = plt.subplots(1, 2, figsize=(14, 8))\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "country.plot(ax=ax[0], edgecolor='darkgray', color='none')\n",
        "gpd.GeoDataFrame(nlss_plot).plot(ax=ax[0], markersize=1, color=cmap(0.35))\n",
        "\n",
        "country.plot(ax=ax[1], edgecolor='darkgray', color='none')\n",
        "dhs_plot.plot(ax=ax[1], markersize=1, color=cmap(0.8))\n",
        "\n",
        "ax[0].set_axis_off()\n",
        "ax[1].set_axis_off()\n",
        "ax[0].set_title('A. NLSS Cluster Locations', fontproperties=bold_font, size=18)\n",
        "ax[1].set_title('B. DHS Cluster Locations', fontproperties=bold_font, size=18)\n",
        "\n",
        "plt.savefig(FIG_PATH + 'cluster_locs.png', dpi=300, bbox_inches='tight', pad_inches=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9bc73IDaa3B"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSmbtzjJaarm"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oD7GhtofyfF"
      },
      "source": [
        "##Make table 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DmbfbFcCcmCV"
      },
      "outputs": [],
      "source": [
        "#@title Table 2 helpers\n",
        "def get_precision(pl_df, num_poor_col, recall=0.10):\n",
        "    n_poor = pl_df[num_poor_col].sum() * recall\n",
        "    included = pl_df[pl_df[num_poor_col].cumsum() <= n_poor]\n",
        "    included_poor = included[num_poor_col].sum()\n",
        "\n",
        "    partial = pl_df[pl_df[num_poor_col].cumsum() >= n_poor].iloc[0]\n",
        "    included_pop = included['pop'].sum() + \\\n",
        "        (n_poor - included_poor) / partial[num_poor_col] * partial['pop']\n",
        "    return n_poor / included_pop\n",
        "\n",
        "def get_table2_row(pl_df, ultrapoor_df=None):\n",
        "    ultrapoor_df = ultrapoor_df if ultrapoor_df is not None else pl_df\n",
        "    prec_poor = get_precision(pl_df, 'asset_poor_w')\n",
        "    prec_ultrapoor = get_precision(ultrapoor_df, 'asset_ultrapoor_w')\n",
        "    return '%.3f, %.3f' % (prec_poor, prec_ultrapoor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HwTeokc4TRsN"
      },
      "outputs": [],
      "source": [
        "#@title Get table 2 (main specification)\n",
        "print('States')\n",
        "print('NLSS', get_table2_row(nlss_pls_state.sort_values('nlss_rwi')))\n",
        "print('ML', get_table2_row(didl_pls_state.sort_values('didl_orig_rwi')))\n",
        "print('DHS', get_table2_row(dhs_pls_state.sort_values('dhs_rwi')))\n",
        "\n",
        "print('LGAs')\n",
        "print('NLSS', get_table2_row(nlss_pls_lga.sort_values('nlss_rwi')))\n",
        "print('ML', get_table2_row(didl_pls_lga.sort_values('didl_orig_rwi')))\n",
        "print('DHS', get_table2_row(noisy_dhs_lga_poor.sort_values('rwi')))\n",
        "print('DHS upper bound', get_table2_row(dhs_pls_lga.sort_values('dhs_rwi')))\n",
        "\n",
        "print('Wards')\n",
        "print('NLSS', get_table2_row(nlss_pls_ward.sort_values('nlss_rwi')))\n",
        "print('ML', get_table2_row(didl_pls_ward.sort_values('didl_orig_rwi')))\n",
        "print('DHS', get_table2_row(noisy_dhs_ward_poor.sort_values('rwi')))\n",
        "print('DHS upper bound', get_table2_row(dhs_pls_ward.sort_values('dhs_rwi')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_FEUCHMUyJY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KvLt3LwpRjPV"
      },
      "outputs": [],
      "source": [
        "#@title Get accuracy figure data\n",
        "def get_acc(pl_df, num_poor_col, frac_targeted):\n",
        "    n_targeted = nlss_pls_ward['asset_poor_w'].sum() * frac_targeted\n",
        "    included = pl_df[pl_df['cum_pop'] <= n_targeted]\n",
        "    included_poor = included[num_poor_col].sum()\n",
        "\n",
        "    partial = pl_df[pl_df['cum_pop'] >= n_targeted].iloc[0]\n",
        "    partial_frac = (n_targeted - included['pop'].sum()) / partial['pop']\n",
        "    included_poor += partial_frac * partial[num_poor_col]\n",
        "\n",
        "    return included_poor / n_targeted, len(included)\n",
        "\n",
        "df = {'acc_didl': [], 'n_didl': [], 'acc_dhs': [], 'n_dhs': [], 'thresh': []}\n",
        "for i in range(1, 101):\n",
        "    acc_didl, n_didl = \\\n",
        "        get_acc(didl_pls_ward.sort_values('didl_orig_rwi'), 'asset_ultrapoor_w', i / 100)\n",
        "    acc_dhs, n_dhs = \\\n",
        "        get_acc(noisy_dhs_ward_ultrapoor.sort_values('rwi'), 'asset_ultrapoor_w', i / 100)\n",
        "\n",
        "    df['acc_didl'].append(acc_didl)\n",
        "    df['n_didl'].append(n_didl)\n",
        "    df['acc_dhs'].append(acc_dhs)\n",
        "    df['n_dhs'].append(n_dhs)\n",
        "    df['thresh'].append(i / 100)\n",
        "\n",
        "df = pd.DataFrame(df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFQ2i7kGWUEe"
      },
      "outputs": [],
      "source": [
        "overlap = df[df['acc_didl'] < df['acc_dhs']]\n",
        "didl_start, didl_end = overlap['n_didl'].min(), overlap['n_didl'].max()\n",
        "dhs_start, dhs_end = overlap['n_dhs'].min(), overlap['n_dhs'].max()\n",
        "\n",
        "didl_wards = didl_pls_ward.sort_values('didl_orig_rwi')[didl_start - 1: didl_end]\n",
        "didl_wards = didl_wards[['ward', 'didl_orig_rwi']]\\\n",
        "    .merge(nlss_pls_ward[['ward', 'asset_ultrapoor', 'nlss_rwi', 'pop']])\n",
        "\n",
        "dhs_wards = noisy_dhs_ward_ultrapoor.sort_values('rwi')[dhs_start - 1: dhs_end]\n",
        "dhs_wards = dhs_wards[['ward', 'rwi']]\\\n",
        "    .merge(nlss_pls_ward[['ward', 'asset_ultrapoor', 'nlss_rwi', 'pop']])\n",
        "\n",
        "didl_wards['nlss_rwi'].mean(), dhs_wards['nlss_rwi'].mean(), \\\n",
        "didl_wards['asset_ultrapoor'].mean(), dhs_wards['asset_ultrapoor'].mean()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q98YjmZld4pm"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3a1IjZFgEzg"
      },
      "source": [
        "##Results for all NLSS LGAs/wards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIfWSveIbO0a",
        "outputId": "74b88be0-9bf1-41d6-f08a-5f428bddad51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "706\n",
            "2016\n",
            "Fraction of NLSS wards with DHS data: 23.0\n",
            "Fraction of all wards with DHS data: 13.8\n",
            "Fraction of NLSS LGAs with DHS data: 84.6\n",
            "Fraction of all LGAs with DHS data: 81.5\n"
          ]
        }
      ],
      "source": [
        "#@title Get PL dfs for full NLSS sample of LGAs and wards\n",
        "# Get data for all NLSS LGAs\n",
        "dhs_imputed_lgas = lgas.merge(dhs_lga, how='left')\\\n",
        "    .merge(dhs_state.rename({'dhs_rwi': 'state_rwi'}, axis=1), how='left')\\\n",
        "    .merge(nlss_lga)\n",
        "dhs_imputed_lgas['dhs_rwi'] = dhs_imputed_lgas['dhs_rwi'].fillna(dhs_imputed_lgas['state_rwi'])\n",
        "\n",
        "nlss_pls_lga_all = get_region_pl_df_uw(lgas, 'lga')\n",
        "dhs_pls_lga_all = get_dhs_pl_df('lga', dhs_imputed_lgas, nlss_pls_lga_all)\n",
        "didl_pls_lga_all = get_didl_pl_df('lga', didl_orig_lga, nlss_pls_lga_all)\n",
        "# get_roc(dhs_pls_lga_all)\n",
        "# get_roc(didl_pls_lga_all)\n",
        "\n",
        "# Get LGA data for all NLSS wards\n",
        "dhs_imputed_wards = wards.merge(dhs_ward, how='left')\\\n",
        "    .merge(dhs_lga.rename({'dhs_rwi': 'lga_rwi'}, axis=1), how='left')\\\n",
        "    .merge(dhs_state.rename({'dhs_rwi': 'state_rwi'}, axis=1), how='left')\\\n",
        "    .merge(nlss_ward)\n",
        "dhs_imputed_wards['dhs_rwi'] = dhs_imputed_wards['dhs_rwi'].fillna(dhs_imputed_wards['lga_rwi'])\\\n",
        "                                                           .fillna(dhs_imputed_wards['state_rwi'])\n",
        "\n",
        "nlss_pls_ward_all = get_region_pl_df_uw(wards, 'ward')\n",
        "dhs_pls_ward_all = get_dhs_pl_df('ward', dhs_imputed_wards, nlss_pls_ward_all)\n",
        "didl_pls_ward_all = get_didl_pl_df('ward', didl_orig_ward, nlss_pls_ward_all)\n",
        "# get_roc(dhs_pls_ward_all)\n",
        "# get_roc(didl_pls_ward_all)\n",
        "\n",
        "print('Fraction of NLSS wards with DHS data: %.1f' % (len(roc_wards) / len(nlss_ward) * 100))\n",
        "print('Fraction of all wards with DHS data: %.1f' % (len(dhs_ward) / len(wards) * 100))\n",
        "\n",
        "print('Fraction of NLSS LGAs with DHS data: %.1f' % (len(roc_lgas) / len(nlss_lga) * 100))\n",
        "print('Fraction of all LGAs with DHS data: %.1f' % (len(dhs_lga) / len(lgas) * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wY2Jwzhfu-K3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BEkSdG-oZNNP"
      },
      "outputs": [],
      "source": [
        "#@title Get table 2, imputing NLSS regions\n",
        "print('LGAs')\n",
        "print('NLSS', get_table2_row(nlss_pls_lga_all.sort_values('nlss_rwi')))\n",
        "print('ML', get_table2_row(didl_pls_lga_all.sort_values('didl_orig_rwi')))\n",
        "print('DHS', get_table2_row(dhs_pls_lga_all.sort_values('dhs_rwi')))\n",
        "\n",
        "print('Wards')\n",
        "print('NLSS', get_table2_row(nlss_pls_ward_all.sort_values('nlss_rwi')))\n",
        "print('ML', get_table2_row(didl_pls_ward_all.sort_values('didl_orig_rwi')))\n",
        "print('DHS', get_table2_row(dhs_pls_ward_all.sort_values('dhs_rwi')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2r-NzNFwenG0"
      },
      "outputs": [],
      "source": [
        "#@title Get ROC\n",
        "print('NLSS')\n",
        "get_roc(nlss_pls_ward_all)\n",
        "print('Satellite')\n",
        "get_roc(didl_pls_ward_all)\n",
        "print('DHS')\n",
        "get_roc(dhs_pls_ward_all)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "e8Um1TMTulZn"
      },
      "outputs": [],
      "source": [
        "#@title Get AUC data for R\n",
        "keep_cols = ['asset_nonpoor_inc', 'asset_poor_inc',\n",
        "             'asset_ultrapoor_inc', 'asset_nonultrapoor_inc']\n",
        "r_ward_nlss = nlss_pls_ward_all[keep_cols]\n",
        "r_ward_didl = didl_pls_ward_all[keep_cols]\n",
        "r_ward_dhs = dhs_pls_ward_all[keep_cols]\n",
        "\n",
        "r_ward_nlss['type'] = 'Optimal'\n",
        "r_ward_didl['type'] = 'Satellite'\n",
        "r_ward_dhs['type'] = 'DHS'\n",
        "\n",
        "r_ward_roc_df = pd.concat([r_ward_nlss, r_ward_didl, r_ward_dhs])\n",
        "r_ward_roc_df.to_csv(OUT_DIR + 'roc_plot_data_all_wards.csv', index=False)\n",
        "r_ward_roc_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uOQ7-EY3arhF"
      },
      "outputs": [],
      "source": [
        "#@title Get accuracy data for R\n",
        "targeting_approach, poor, ultrapoor, thresh = [], [], [], []\n",
        "nlss_pls_ward_all = nlss_pls_ward_all.sort_values('nlss_rwi')\n",
        "didl_pls_ward_all = didl_pls_ward_all.sort_values('didl_orig_rwi')\n",
        "dhs_pls_ward_all = dhs_pls_ward_all.sort_values('dhs_rwi')\n",
        "\n",
        "for i in range(1, 100):\n",
        "    thresh += [i / 100] * 3\n",
        "    targeting_approach += ['Optimal', 'Satellite', 'DHS']\n",
        "    poor += [get_precision(nlss_pls_ward_all, 'asset_poor_w', recall=i/100),\n",
        "             get_precision(didl_pls_ward_all, 'asset_poor_w', recall=i/100),\n",
        "             get_precision(dhs_pls_ward_all, 'asset_poor_w', recall=i/100)]\n",
        "    ultrapoor += [get_precision(nlss_pls_ward_all, 'asset_ultrapoor_w', recall=i/100),\n",
        "                  get_precision(didl_pls_ward_all, 'asset_ultrapoor_w', recall=i/100),\n",
        "                  get_precision(dhs_pls_ward_all, 'asset_ultrapoor_w', recall=i/100)]\n",
        "\n",
        "acc_df = pd.DataFrame({'targeting_approach': targeting_approach, 'poor': poor,\n",
        "                       'verypoor': ultrapoor, 'thresh': thresh})\n",
        "acc_df.to_csv(OUT_DIR + 'acc_plot_data_all_wards.csv', index=False)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQOkHqiSqZRa"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdCFfLi1sGuL"
      },
      "source": [
        "# Target with DHS as gt and NLSS as survey benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m41JYPDHncY0",
        "outputId": "85058d04-47f8-4a32-f312-1ad9f8696daa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.40532921993869897 0.08207280524503148\n"
          ]
        }
      ],
      "source": [
        "#@title Make DHS poverty line df\n",
        "\n",
        "print(poor_thresh, ultrapoor_thresh)\n",
        "\n",
        "dhs_pls = dhs_eval[['weight', 'dhs_rwi', 'ward', 'lga', 'geo_state']]\\\n",
        "    .rename({'geo_state': 'state'}, axis=1)\n",
        "dhs_pls['popw'] = dhs_pls['weight'] * (nlss_pls['popw'].sum() / dhs_pls['weight'].sum())\n",
        "dhs_pls['dhs_rwi_w'] = dhs_pls['dhs_rwi'] * dhs_pls['popw']\n",
        "\n",
        "dhs_pls = get_weighted_quantile(dhs_pls, 'dhs_rwi', 'weight', 'dhs_rwi_q')\n",
        "pop_reweight = states['pop'].sum() / dhs_pls['popw'].sum()\n",
        "\n",
        "dhs_pls['asset_poor'] = dhs_pls['dhs_rwi_q'].apply(lambda x: 0 if x > poor_thresh else 1)\n",
        "dhs_pls['asset_ultrapoor'] = dhs_pls['dhs_rwi_q'].apply(lambda x: 0 if x > ultrapoor_thresh else 1)\n",
        "\n",
        "dhs_pls['asset_poor_w'] = dhs_pls.apply(\n",
        "    lambda x: x['asset_poor'] * x['popw'] * pop_reweight, axis=1)\n",
        "dhs_pls['asset_ultrapoor_w'] = dhs_pls.apply(\n",
        "    lambda x: x['asset_ultrapoor'] * x['popw'] * pop_reweight, axis=1)\n",
        "\n",
        "total_poor = states['pop'].sum() * poor_thresh\n",
        "total_ultrapoor = states['pop'].sum() * ultrapoor_thresh\n",
        "total_nonpoor = states['pop'].sum() * (1 - poor_thresh)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QFWNb5slysx_"
      },
      "outputs": [],
      "source": [
        "#@title DHS state level targeting DF\n",
        "dhs_gt_pls_state = dhs_pls.groupby('state')\\\n",
        "    [['dhs_rwi_w', 'asset_poor_w', 'asset_ultrapoor_w']]\\\n",
        "    .sum().reset_index().merge(states)\n",
        "\n",
        "dhs_gt_pls_state['dhs_rwi'] = dhs_gt_pls_state['dhs_rwi_w'] \\\n",
        "    / dhs_gt_pls_state['pop']\n",
        "dhs_gt_pls_state = dhs_gt_pls_state.sort_values(by='dhs_rwi')\\\n",
        "                                   .drop('dhs_rwi_w', axis=1)\n",
        "dhs_gt_pls_state['cum_pop'] = dhs_gt_pls_state['pop'].cumsum()\n",
        "\n",
        "dhs_gt_pls_state['asset_poor_inc'] = dhs_gt_pls_state['asset_poor_w'].cumsum() \\\n",
        "    / total_poor\n",
        "dhs_gt_pls_state['asset_ultrapoor_inc'] = dhs_gt_pls_state['asset_ultrapoor_w']\\\n",
        "    .cumsum() / total_ultrapoor\n",
        "dhs_gt_pls_state['asset_nonpoor_inc'] = (dhs_gt_pls_state['cum_pop'] -\n",
        "    dhs_gt_pls_state['asset_poor_w'].cumsum()) \\\n",
        "    / (states['pop'].sum() * (1 - poor_thresh))\n",
        "dhs_gt_pls_state['asset_nonultrapoor_inc'] = (dhs_gt_pls_state['cum_pop'] -\n",
        "    dhs_gt_pls_state['asset_ultrapoor_w'].cumsum()) \\\n",
        "    / (states['pop'].sum() * (1 - ultrapoor_thresh))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqjiGWoIysPG"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoR8LuTIqZPN",
        "outputId": "d64cebff-65ba-4af0-9a91-bd039db3e442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "597\n",
            "Asset poor frac, lgas: 0.4\n",
            "Asset very poor frac, lgas: 0.0819\n",
            "464\n",
            "Asset poor frac, wards: 0.271\n",
            "Asset very poor frac, wards: 0.0541\n"
          ]
        }
      ],
      "source": [
        "#@title DHS LGA and ward level targeting DFs\n",
        "# DHS poverty lines, LGA\n",
        "dhs_gt_pls_lga = get_region_pl_df_uw(roc_lgas, 'lga', 'dhs_rwi_w', 'dhs_rwi', dhs_pls)\n",
        "print('Asset poor frac, lgas:', round(dhs_gt_pls_lga['asset_poor_w'].sum() /\n",
        "                                      dhs_gt_pls_lga['pop'].sum(), 3))\n",
        "print('Asset very poor frac, lgas:', round(dhs_gt_pls_lga['asset_ultrapoor_w'].sum() /\n",
        "                                           dhs_gt_pls_lga['pop'].sum(), 4))\n",
        "\n",
        "# DHS poverty lines, ward\n",
        "dhs_gt_pls_ward = get_region_pl_df_uw(roc_wards, 'ward', 'dhs_rwi_w', 'dhs_rwi', dhs_pls)\n",
        "print('Asset poor frac, wards:', round(dhs_gt_pls_ward['asset_poor_w'].sum() /\n",
        "                                       dhs_gt_pls_ward['pop'].sum(), 3))\n",
        "print('Asset very poor frac, wards:', round(dhs_gt_pls_ward['asset_ultrapoor_w'].sum() /\n",
        "                                            dhs_gt_pls_ward['pop'].sum(), 4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4Zz82cKxw3V1"
      },
      "outputs": [],
      "source": [
        "# @title Get DIDL data for ROC plot, DHS ground truth\n",
        "didl_pls_state_dhsgt = get_didl_pl_df('state', didl_orig_state, dhs_gt_pls_state)\n",
        "didl_pls_lga_dhsgt = get_didl_pl_df('lga', didl_orig_lga, dhs_gt_pls_lga)\n",
        "didl_pls_ward_dhsgt = get_didl_pl_df('ward', didl_orig_ward, dhs_gt_pls_ward)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD7VhA7e0b_O",
        "outputId": "cf6c2450-0ce4-4efa-e99c-cdb0a0549391"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(597, 597)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jy7rxeS7xf5D"
      },
      "outputs": [],
      "source": [
        "#@title Get NLSS data for ROC plot, DHS ground truth\n",
        "\n",
        "def get_pl_df(groupby_col, eval_reg, gt_reg, eval_rwi_col):\n",
        "    eval_pls_reg = gt_reg.merge(eval_reg[[groupby_col, eval_rwi_col]])\\\n",
        "                              .sort_values(by=eval_rwi_col)\n",
        "    return get_inc_ex(eval_pls_reg)\n",
        "\n",
        "nlss_pls_state_dhsgt = get_pl_df('state', nlss_pls_state, dhs_gt_pls_state, 'nlss_rwi')\n",
        "nlss_pls_lga_dhsgt = get_pl_df('lga', nlss_pls_lga, dhs_gt_pls_lga, 'nlss_rwi')\n",
        "nlss_pls_ward_dhsgt = get_pl_df('ward', nlss_pls_ward, dhs_gt_pls_ward, 'nlss_rwi')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz12gJ0AqZNK",
        "outputId": "b2e8ea0c-ea08-4301-d491-5dc2f3b2d517"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.656\n"
          ]
        }
      ],
      "source": [
        "#@title Make imputed NLSS df -- LGAs, DHS ground truth\n",
        "def impute_lga_with_state_dhsgt(row):\n",
        "    drop_lga_df = nlss_hhs_dhsgt.loc[(nlss_hhs_dhsgt['lga'] != row['lga']) &\n",
        "                                     (nlss_hhs_dhsgt['state'] == row['state'])]\n",
        "    return drop_lga_df['nlss_rwi_w'].sum() / drop_lga_df['popw'].sum()\n",
        "\n",
        "nlss_hhs_dhsgt = nlss_hhs.copy()\n",
        "nlss_hhs_dhsgt['nlss_rwi_w'] = nlss_hhs_dhsgt['popw'] * standardize(nlss_hhs_dhsgt['nlss_rwi'])\n",
        "\n",
        "nlss_lga_impute = nlss_lga.merge(lgas[['lga', 'state']]) #, how='right')\n",
        "nlss_lga_impute['imputed_rwi'] = nlss_lga_impute.apply(impute_lga_with_state_dhsgt, axis=1)\n",
        "print(round(pearsonr(nlss_lga_impute['imputed_rwi'], nlss_lga_impute['nlss_rwi'])[0], 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhBkTtbVuZ7K",
        "outputId": "b2ab460f-7622-46e8-916c-72f43145a0cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016\n",
            "0.566\n"
          ]
        }
      ],
      "source": [
        "#@title Make imputed NLSS df -- wards, DHS ground truth\n",
        "def impute_ward_with_lga_dhsgt(row):\n",
        "    drop_ward_df = nlss_hhs_dhsgt.loc[(nlss_hhs_dhsgt['ward'] != row['ward']) &\n",
        "                                      (nlss_hhs_dhsgt['lga'] == row['lga'])]\n",
        "    if len(drop_ward_df) == 0:\n",
        "        return None\n",
        "    return drop_ward_df['nlss_rwi_w'].sum() / drop_ward_df['popw'].count()\n",
        "\n",
        "nlss_hhs_dhsgt['nlss_rwi'] = standardize(nlss_hhs_dhsgt['nlss_rwi'])\n",
        "nlss_ward_impute = nlss_ward.merge(wards[['ward', 'lga']]) #, how='right')\n",
        "\n",
        "nlss_ward_impute['imputed_rwi'] = nlss_ward_impute.apply(impute_ward_with_lga_dhsgt, axis=1)\n",
        "\n",
        "nlss_ward_impute = nlss_ward_impute.merge(nlss_lga_impute[['lga', 'imputed_rwi']].\n",
        "                                          rename({'imputed_rwi': 'state_rwi'}, axis=1),\n",
        "                                          on='lga')\n",
        "print(len(nlss_ward_impute))\n",
        "nlss_ward_impute.loc[nlss_ward_impute['imputed_rwi'].isna(), 'imputed_rwi'] = \\\n",
        "    nlss_ward_impute.loc[nlss_ward_impute['imputed_rwi'].isna(), 'state_rwi']\n",
        "\n",
        "print(round(pearsonr(nlss_ward_impute['imputed_rwi'], nlss_ward_impute['nlss_rwi'])[0], 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON7EBloMncSz",
        "outputId": "b34b7dd8-292a-47cd-ba2e-779ee2af3cea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "52 597\n"
          ]
        }
      ],
      "source": [
        "#@title Bootstrap LGAs w imputation, NLSS - DHS ground truth\n",
        "np.random.seed(123)\n",
        "\n",
        "n_to_replace = round((1 - (len(nlss_lga) / len(lgas))) * len(nlss_pls_lga))\n",
        "nlss_lga_impute = nlss_lga_impute[nlss_lga_impute['lga'].isin(roc_lgas['lga'])]\n",
        "print(n_to_replace, len(nlss_lga_impute))\n",
        "\n",
        "lga_output = []\n",
        "b = 1000\n",
        "for i in range(b):\n",
        "    lga_pls_i = get_random_roc('lga', lgas, n_to_replace, nlss_lga_impute,\n",
        "                               dhs_gt_pls_lga, 'nlss_rwi')\n",
        "    lga_output += [(get_auc(lga_pls_i, 'asset_nonpoor_inc', 'asset_poor_inc'),\n",
        "                    get_auc(lga_pls_i, 'asset_nonultrapoor_inc', 'asset_ultrapoor_inc'),\n",
        "                    lga_pls_i)]\n",
        "\n",
        "noisy_nlss_lga_poor = sorted(lga_output, key=lambda x: x[0])[int(b / 2) - 1][2]\n",
        "noisy_nlss_lga_ultrapoor = sorted(lga_output, key=lambda x: x[1])[int(b / 2) - 1][2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx2nFFwmncOu",
        "outputId": "4f2365a9-eb12-4c9e-f634-a097fa9827f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "358 464\n"
          ]
        }
      ],
      "source": [
        "#@title Bootstrap wards w imputation, NLSS - DHS ground truth\n",
        "np.random.seed(123)\n",
        "\n",
        "n_to_replace = round((1 - (len(nlss_ward) / len(wards))) * len(nlss_pls_ward))\n",
        "nlss_ward_impute = nlss_ward_impute[nlss_ward_impute['ward'].isin(roc_wards['ward'])]\n",
        "print(n_to_replace, len(nlss_ward_impute))\n",
        "\n",
        "ward_output = []\n",
        "for i in range(b):\n",
        "    ward_pls_i = get_random_roc('ward', wards, n_to_replace, nlss_ward_impute,\n",
        "                                dhs_gt_pls_ward, 'nlss_rwi')\n",
        "    ward_output += [(get_auc(ward_pls_i, 'asset_nonpoor_inc', 'asset_poor_inc'),\n",
        "                     get_auc(ward_pls_i, 'asset_nonultrapoor_inc', 'asset_ultrapoor_inc'),\n",
        "                     ward_pls_i)]\n",
        "\n",
        "noisy_nlss_ward_poor = sorted(ward_output, key=lambda x: x[0])[int(b / 2) - 1][2]\n",
        "noisy_nlss_ward_ultrapoor = sorted(ward_output, key=lambda x: x[1])[int(b / 2) - 1][2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wZ02OMQ9FjH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhKNOAdlncLo",
        "outputId": "098b7e99-b41f-4a40-f0f1-4745203f833a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DHS\n",
            "poor 0.812 very poor 0.83\n",
            "poor 0.918 very poor 0.922\n",
            "poor 0.955 very poor 0.96\n",
            "\n",
            "Satellite\n",
            "poor 0.799 very poor 0.824\n",
            "poor 0.871 very poor 0.856\n",
            "poor 0.904 very poor 0.876\n",
            "\n",
            "NLSS\n",
            "poor 0.816 very poor 0.852\n",
            "poor 0.844 very poor 0.832\n",
            "poor 0.844 very poor 0.834\n",
            "poor 0.808 very poor 0.816\n",
            "poor 0.815 very poor 0.817\n"
          ]
        }
      ],
      "source": [
        "#@title Get ROC - DHS ground truth\n",
        "print('DHS')\n",
        "get_roc(dhs_gt_pls_state)\n",
        "get_roc(dhs_gt_pls_lga)\n",
        "get_roc(dhs_gt_pls_ward)\n",
        "print('\\nSatellite')\n",
        "get_roc(didl_pls_state_dhsgt)\n",
        "get_roc(didl_pls_lga_dhsgt)\n",
        "get_roc(didl_pls_ward_dhsgt)\n",
        "print('\\nNLSS')\n",
        "get_roc(nlss_pls_state_dhsgt)\n",
        "get_roc(noisy_nlss_lga_poor)\n",
        "get_roc(noisy_nlss_lga_ultrapoor)\n",
        "get_roc(noisy_nlss_ward_poor)\n",
        "get_roc(noisy_nlss_ward_ultrapoor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0jzwJRHncCV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cW_YJE9smj9a"
      },
      "outputs": [],
      "source": [
        "#@title Get ward data for R - DHS ground truth\n",
        "keep_cols = ['asset_nonpoor_inc', 'asset_poor_inc',\n",
        "             'asset_ultrapoor_inc', 'asset_nonultrapoor_inc']\n",
        "r_ward_dhs = dhs_gt_pls_ward[keep_cols]\n",
        "r_ward_didl = didl_pls_ward_dhsgt[keep_cols]\n",
        "# r_ward_dhs = dhs_pls_ward[keep_cols]\n",
        "r_noisy_nlss_ward_poor = noisy_nlss_ward_poor[keep_cols]\\\n",
        "    .sort_values('asset_nonpoor_inc')\n",
        "r_noisy_nlss_ward_ultrapoor = noisy_nlss_ward_ultrapoor[keep_cols]\\\n",
        "    .sort_values('asset_nonultrapoor_inc')\n",
        "\n",
        "r_ward_dhs['type'] = 'Optimal - DHS'\n",
        "r_ward_didl['type'] = 'Satellite'\n",
        "# r_ward_dhs['type'] = 'DHS'\n",
        "r_noisy_nlss_ward_poor['type'] = 'Survey Benchmark - NLSS'\n",
        "r_noisy_nlss_ward_ultrapoor['type'] = 'Survey Benchmark - NLSS'\n",
        "\n",
        "r_ward_roc_df_poor = pd.concat([r_ward_dhs, r_ward_didl, #r_ward_dhs,\n",
        "                                r_noisy_nlss_ward_poor])\n",
        "r_ward_roc_df_poor.to_csv(OUT_DIR + 'ward_roc_poor_dhsgt.csv', index=False)\n",
        "r_ward_roc_df_ultrapoor = pd.concat([r_ward_dhs, r_ward_didl, #r_ward_dhs,\n",
        "                                     r_noisy_nlss_ward_ultrapoor])\n",
        "r_ward_roc_df_ultrapoor.to_csv(OUT_DIR + 'ward_roc_ultrapoor_dhsgt.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_s5Si-Amj5s"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ii69zI9zmj2q"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqqiBlYomjtg"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjhJKHBY6Auc"
      },
      "source": [
        "# Misc. appendix plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9sElDVTzTuN"
      },
      "source": [
        "## Coverage fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CKJIi1Xzmb9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Get data\n",
        "didl_orig_all['estimated_rwi'] = standardize(didl_orig_all['estimated_rwi'])\n",
        "# plot_wards = wards[['ward', 'geometry']].merge(didl_orig_ward)\n",
        "plot_lgas = lgas[['lga', 'geometry']].merge(didl_orig_lga)\n",
        "plot_lgas['didl_orig_rwi'] = standardize(plot_lgas['didl_orig_rwi'])\n",
        "plot_lgas.plot(ax=ax, column='didl_orig_rwi', edgecolor='none', cmap='afmhot')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYwTqIxayGXq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Make figure\n",
        "sns.set_style('white')\n",
        "f, ax = plt.subplots(3, 2, figsize=(14, 24))\n",
        "plt.subplots_adjust(wspace=0, hspace=-0.4)\n",
        "\n",
        "for row in range(3):\n",
        "    for col in range(2):\n",
        "        country.plot(ax=ax[row][col], edgecolor='darkgray', color='none')\n",
        "        for spine in ['top', 'bottom', 'left', 'right']:\n",
        "            ax[row][col].spines[spine].set_visible(False)\n",
        "        ax[row][col].xaxis.set_ticks([])\n",
        "        ax[row][col].yaxis.set_ticks([])\n",
        "\n",
        "    wards.plot(ax=ax[row][0], edgecolor='darkgray', color='none', linewidth=0.2)\n",
        "    lgas.plot(ax=ax[row][1], edgecolor='darkgray', color='none', linewidth=0.2)\n",
        "    \n",
        "nlss_wards.plot(ax=ax[0][0], edgecolor='darkgray', color='black', linewidth=0.2)\n",
        "didl_wards.plot(ax=ax[1][0], edgecolor='darkgray', color='#548b54', linewidth=0.2)\n",
        "dhs_wards.plot(ax=ax[2][0], edgecolor='darkgray', color='lightblue', linewidth=0.2)\n",
        "\n",
        "nlss_lgas.plot(ax=ax[0][1], edgecolor='darkgray', color='black', linewidth=0.2)\n",
        "didl_lgas.plot(ax=ax[1][1], edgecolor='darkgray', color='#548b54', linewidth=0.2)\n",
        "dhs_lgas.plot(ax=ax[2][1], edgecolor='darkgray', color='lightblue', linewidth=0.2)\n",
        "\n",
        "ax[0][0].set_title('A. Wards Targeted', fontproperties=bold_font, size=18)\n",
        "ax[0][1].set_title('B. LGAs Targeted', fontproperties=bold_font, size=18)\n",
        "\n",
        "ax[0][0].set_ylabel('Optimal (NLSS)', fontproperties=bold_font, size=18)\n",
        "ax[1][0].set_ylabel('ML-Based', fontproperties=bold_font, size=18)\n",
        "ax[2][0].set_ylabel('Survey Benchmark', fontproperties=bold_font, size=18)\n",
        "# plt.savefig(FIG_PATH + 'targeted_units_10pct.png', dpi=300, bbox_inches='tight', pad_inches=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "im9gFaTAzRfl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-VSXfNNzSNE"
      },
      "source": [
        "## Appendix figs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pbs4azSwO3yN"
      },
      "outputs": [],
      "source": [
        "#@title Get regions at 10% of pop targeted, original sample\n",
        "frac = 0.1\n",
        "to_target = nlss_pls_lga['pop'].sum() * frac\n",
        "\n",
        "def get_regions(df, frac, region_col, region_df):\n",
        "    n = df['pop'].sum() * frac\n",
        "    full = df.loc[df['cum_pop'] < n, [region_col]].assign(partial=0)\n",
        "    partial = df.loc[df['cum_pop'] >= n][[region_col]].assign(partial=1)[:1]\n",
        "    return region_df.merge(full) #region_df.merge(pd.concat([full, partial]))\n",
        "\n",
        "nlss_lgas = get_regions(nlss_pls_lga.sort_values('nlss_rwi'), 0.1, 'lga', lgas)\n",
        "dhs_lgas = get_regions(noisy_dhs_lga_poor.sort_values('rwi'), 0.1, 'lga', lgas)\n",
        "didl_lgas = get_regions(didl_pls_lga.sort_values('didl_orig_rwi'), 0.1, 'lga', lgas)\n",
        "\n",
        "nlss_wards = get_regions(nlss_pls_ward.sort_values('nlss_rwi'), 0.1, 'ward', wards)\n",
        "dhs_wards = get_regions(noisy_dhs_ward_poor.sort_values('rwi'), 0.1, 'ward', wards)\n",
        "didl_wards = get_regions(didl_pls_ward.sort_values('didl_orig_rwi'), 0.1, 'ward', wards)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHDJUTG8lKZY",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Plot regions at 10\\% of pop targeted, original sample\n",
        "# TODO: make partial a diff color?\n",
        "import matplotlib.font_manager as fm\n",
        "bold_font = fm.FontProperties(\n",
        "    fname='drive/MyDrive/poverty_map_paper/Latin-Modern-Roman/lmroman10-bold.otf')\n",
        "\n",
        "sns.set_style('white')\n",
        "f, ax = plt.subplots(3, 2, figsize=(14, 24))\n",
        "plt.subplots_adjust(wspace=0, hspace=-0.4)\n",
        "\n",
        "for row in range(3):\n",
        "    for col in range(2):\n",
        "        country.plot(ax=ax[row][col], edgecolor='darkgray', color='none')\n",
        "        for spine in ['top', 'bottom', 'left', 'right']:\n",
        "            ax[row][col].spines[spine].set_visible(False)\n",
        "        ax[row][col].xaxis.set_ticks([])\n",
        "        ax[row][col].yaxis.set_ticks([])\n",
        "\n",
        "    wards.plot(ax=ax[row][0], edgecolor='darkgray', color='none', linewidth=0.2)\n",
        "    lgas.plot(ax=ax[row][1], edgecolor='darkgray', color='none', linewidth=0.2)\n",
        "    \n",
        "nlss_wards.plot(ax=ax[0][0], edgecolor='darkgray', color='black', linewidth=0.2)\n",
        "didl_wards.plot(ax=ax[1][0], edgecolor='darkgray', color='#548b54', linewidth=0.2)\n",
        "dhs_wards.plot(ax=ax[2][0], edgecolor='darkgray', color='lightblue', linewidth=0.2)\n",
        "\n",
        "nlss_lgas.plot(ax=ax[0][1], edgecolor='darkgray', color='black', linewidth=0.2)\n",
        "didl_lgas.plot(ax=ax[1][1], edgecolor='darkgray', color='#548b54', linewidth=0.2)\n",
        "dhs_lgas.plot(ax=ax[2][1], edgecolor='darkgray', color='lightblue', linewidth=0.2)\n",
        "\n",
        "ax[0][0].set_title('A. Wards Targeted', fontproperties=bold_font, size=18)\n",
        "ax[0][1].set_title('B. LGAs Targeted', fontproperties=bold_font, size=18)\n",
        "\n",
        "ax[0][0].set_ylabel('Optimal (NLSS)', fontproperties=bold_font, size=18)\n",
        "ax[1][0].set_ylabel('ML-Based', fontproperties=bold_font, size=18)\n",
        "ax[2][0].set_ylabel('Survey Benchmark', fontproperties=bold_font, size=18)\n",
        "plt.savefig(FIG_PATH + 'targeted_units_10pct.png', dpi=300, bbox_inches='tight', pad_inches=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_wfNRNT0-9Q"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jbHgO9MeIIq7"
      },
      "outputs": [],
      "source": [
        "#@title Make appendix table of overlap/wealth of targeted regions \n",
        "\n",
        "def frac_of_1_in_2(df1, df2, reg):\n",
        "    overlap = df1[df1[reg].isin(df2[reg])]\n",
        "    one_only = df1[~df1[reg].isin(df2[reg])]\n",
        "    return round(len(overlap) / len(df1), 3)\n",
        "\n",
        "    # rwi_overlap = (overlap['nlss_rwi'] * overlap['pop']).sum() / overlap['pop'].sum()\n",
        "    # rwi_one_only = (one_only['nlss_rwi'] * one_only['pop']).sum() / one_only['pop'].sum()\n",
        "    # print('Fraction of wards from one in two:', round(len(overlap) / len(df1), 3))\n",
        "    # print('RWI of overlap:', round(rwi_overlap, 3))\n",
        "    # print('RWI of one only:', round(rwi_one_only, 3))\n",
        "\n",
        "def mean_wealth(df, rwi_df):\n",
        "    wealth_df = df.merge(rwi_df)\n",
        "    return round((wealth_df['nlss_rwi'] * wealth_df['pop']).sum() / wealth_df['pop'].sum(), 3)\n",
        "\n",
        "lga_rwi = nlss_pls_lga[['lga', 'nlss_rwi']]\n",
        "ward_rwi = nlss_pls_ward[['ward', 'nlss_rwi']]\n",
        "\n",
        "print('LGAs')\n",
        "print('Fraction of selected chosen under optimal targeting')\n",
        "print(frac_of_1_in_2(nlss_lgas, nlss_lgas, 'lga'),\n",
        "      frac_of_1_in_2(didl_lgas, nlss_lgas, 'lga'),\n",
        "      frac_of_1_in_2(dhs_lgas, nlss_lgas, 'lga'))\n",
        "print('Mean wealth, all selected')\n",
        "print(mean_wealth(nlss_lgas, lga_rwi),\n",
        "      mean_wealth(didl_lgas, lga_rwi),\n",
        "      mean_wealth(dhs_lgas, lga_rwi))\n",
        "print('Mean wealth, optimal selected')\n",
        "print(mean_wealth(nlss_lgas[nlss_lgas['lga'].isin(nlss_lgas['lga'])], lga_rwi),\n",
        "      mean_wealth(didl_lgas[didl_lgas['lga'].isin(nlss_lgas['lga'])], lga_rwi),\n",
        "      mean_wealth(dhs_lgas[dhs_lgas['lga'].isin(nlss_lgas['lga'])], lga_rwi))\n",
        "print('Mean wealth, non-optimal selected')\n",
        "print('---',\n",
        "      mean_wealth(didl_lgas[~didl_lgas['lga'].isin(nlss_lgas['lga'])], lga_rwi),\n",
        "      mean_wealth(dhs_lgas[~dhs_lgas['lga'].isin(nlss_lgas['lga'])], lga_rwi))\n",
        "\n",
        "print('\\nWards')\n",
        "print('Fraction of selected chosen under optimal targeting')\n",
        "print(frac_of_1_in_2(nlss_wards, nlss_wards, 'ward'),\n",
        "      frac_of_1_in_2(didl_wards, nlss_wards, 'ward'),\n",
        "      frac_of_1_in_2(dhs_wards, nlss_wards, 'ward'))\n",
        "print('Mean wealth, all selected')\n",
        "print(mean_wealth(nlss_wards, ward_rwi),\n",
        "      mean_wealth(didl_wards, ward_rwi),\n",
        "      mean_wealth(dhs_wards, ward_rwi))\n",
        "print('Mean wealth, optimal selected')\n",
        "print(mean_wealth(nlss_wards[nlss_wards['ward'].isin(nlss_wards['ward'])], ward_rwi),\n",
        "      mean_wealth(didl_wards[didl_wards['ward'].isin(nlss_wards['ward'])], ward_rwi),\n",
        "      mean_wealth(dhs_wards[dhs_wards['ward'].isin(nlss_wards['ward'])], ward_rwi))\n",
        "print('Mean wealth, non-optimal selected')\n",
        "print('---',\n",
        "      mean_wealth(didl_wards[~didl_wards['ward'].isin(nlss_wards['ward'])], ward_rwi),\n",
        "      mean_wealth(dhs_wards[~dhs_wards['ward'].isin(nlss_wards['ward'])], ward_rwi))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1Yz2vjYxHaM",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Quantify overlap\n",
        "def num_of_1_in_2(df1, df2, reg):\n",
        "    overlap = df1[df1[reg].isin(df2[reg])]\n",
        "    one_only = df1[~df1[reg].isin(df2[reg])]\n",
        "    return len(overlap)\n",
        "\n",
        "print(len(nlss_lgas), len(didl_lgas), len(dhs_lgas))\n",
        "print(num_of_1_in_2(nlss_lgas, nlss_lgas, 'lga'), \\\n",
        "        num_of_1_in_2(didl_lgas, nlss_lgas, 'lga'), \\\n",
        "        num_of_1_in_2(dhs_lgas, nlss_lgas, 'lga'))\n",
        "print(len(nlss_lgas) - num_of_1_in_2(nlss_lgas, nlss_lgas, 'lga'), \\\n",
        "        len(didl_lgas) - num_of_1_in_2(didl_lgas, nlss_lgas, 'lga'), \\\n",
        "        len(dhs_lgas) - num_of_1_in_2(dhs_lgas, nlss_lgas, 'lga'))\n",
        "\n",
        "print(len(nlss_wards), len(didl_wards), len(dhs_wards))\n",
        "print(num_of_1_in_2(nlss_wards, nlss_wards, 'ward'), \\\n",
        "        num_of_1_in_2(didl_wards, nlss_wards, 'ward'), \\\n",
        "        num_of_1_in_2(dhs_wards, nlss_wards, 'ward'))\n",
        "print(len(nlss_wards) - num_of_1_in_2(nlss_wards, nlss_wards, 'ward'), \\\n",
        "        len(didl_wards) - num_of_1_in_2(didl_wards, nlss_wards, 'ward'), \\\n",
        "        len(dhs_wards) - num_of_1_in_2(dhs_wards, nlss_wards, 'ward'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RO99zFZhxHN1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Eup98XvKoFJ9"
      },
      "outputs": [],
      "source": [
        "#@title DIDL ward rank vs NLSS coverage data for R\n",
        "didl_orig_ward['in_nlss'] = 0\n",
        "didl_orig_ward.loc[didl_orig_ward['ward'].isin(nlss_ward['ward']), 'in_nlss'] = 1\n",
        "didl_orig_ward = didl_orig_ward.sort_values('didl_orig_rwi')\n",
        "didl_orig_ward['frac_in_nlss'] = didl_orig_ward['in_nlss'].expanding().mean()\n",
        "didl_orig_ward['n_wards_targeted'] = didl_orig_ward['didl_orig_rwi'].rank()\n",
        "\n",
        "didl_orig_ward.to_csv(OUT_DIR + 'ml_wards_in_nlss.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OvnYT1Y0lKQt"
      },
      "outputs": [],
      "source": [
        "#@title Correlation between ML and NLSS wards furthest from DHS clusters\n",
        "# warning - this takes ~6min\n",
        "\n",
        "# nlss_ward_locs = wards[['ward', 'geometry']].merge(\n",
        "#     nlss_ward[~nlss_ward['ward'].isin(dhs_ward['ward'])])\n",
        "# nlss_ward_locs = nlss_ward_locs.to_crs(epsg=3310)\n",
        "# ref = dhs_eval.to_crs(epsg=3310)\n",
        "\n",
        "# nlss_ward_locs['nearest_dhs_cluster'] = nlss_ward_locs['geometry'].apply(\n",
        "#     lambda x: ref['geometry'].apply(lambda y: x.distance(y)).min() / 1000\n",
        "# )\n",
        "\n",
        "# nlss_ward_locs.rename({'nearest_dhs_ward': 'nearest_dhs_cluster'}, axis=1)\\\n",
        "#     [['ward', 'nearest_dhs_cluster']].to_csv(\n",
        "#     DATA_PATH + 'nlss/nearest_dhs_cluster.csv', index=False)\n",
        "\n",
        "nlss_ward_locs = pd.read_csv(DATA_PATH + 'nlss/nearest_dhs_cluster.csv')\\\n",
        "                   .merge(didl_orig_ward[['ward', 'didl_orig_rwi']])\\\n",
        "                   .merge(nlss_ward[['ward', 'nlss_rwi']])\\\n",
        "                   .sort_values('nearest_dhs_cluster', ascending=False)\n",
        "nlss_counts = nlss_hhs.groupby('ward')['hhid'].nunique().reset_index()\n",
        "nlss_ward_locs = nlss_ward_locs.merge(nlss_counts)\n",
        "\n",
        "print('All wards')\n",
        "for i in [0, 1, 5, 10, 15, 20]:\n",
        "    df = nlss_ward_locs[nlss_ward_locs['nearest_dhs_cluster'] >= i]\n",
        "    rho, p, ci = get_r_ci(df, 'didl_orig_rwi', 'nlss_rwi')\n",
        "    print('nearest DHS ward >=', i,\n",
        "          '| n =', len(df),\n",
        "          '| rho=%.3f (%.3f, %.3f), (p=%.2e)' % (rho, ci[0], ci[1], p))\n",
        "    \n",
        "# print('> 20 households')\n",
        "# for i in [0, 1, 5, 10, 15, 20]:\n",
        "#     df = nlss_ward_locs[(nlss_ward_locs['nearest_dhs_cluster'] >= i) &\n",
        "#                     (nlss_ward_locs['hhid'] >= 20)]\n",
        "#     rho, p, ci = get_r_ci(df, 'didl_orig_rwi', 'nlss_rwi')\n",
        "#     print('nearest DHS ward >=', i,\n",
        "#           '| n =', len(df),\n",
        "#           '| rho=%.3f (%.3f, %.3f), (p=%.2e)' % (rho, ci[0], ci[1], p))\n",
        "\n",
        "nlss_ward_locs = wards[['ward', 'geometry']]\n",
        "nlss_ward_locs = nlss_ward_locs.to_crs(epsg=3310)\n",
        "ref = dhs_eval.to_crs(epsg=3310)\n",
        "\n",
        "nlss_ward_locs['nearest_dhs_cluster'] = nlss_ward_locs['geometry'].apply(\n",
        "    lambda x: ref['geometry'].apply(lambda y: x.distance(y)).min() / 1000\n",
        ")\n",
        "\n",
        "nlss_ward_locs.rename({'nearest_dhs_ward': 'nearest_dhs_cluster'}, axis=1)\\\n",
        "    [['ward', 'nearest_dhs_cluster']].to_csv(\n",
        "    DATA_PATH + 'nlss/nearest_dhs_cluster_all.csv', index=False)\n",
        "\n",
        "nlss_ward_locs = nlss_ward_locs.merge(wards[['ward', 'state', 'pop']])\n",
        "gt10 = nlss_ward_locs[nlss_ward_locs['nearest_dhs_cluster'] > 10]\n",
        "print(1 - len(gt10) / len(nlss_ward_locs), 1 - gt10['pop'].sum() / nlss_ward_locs['pop'].sum())\n",
        "\n",
        "gt10_nb = gt10[gt10['state'] != 'borno']\n",
        "1 - len(gt10_nb) / len(nlss_ward_locs[nlss_ward_locs['state'] != 'borno']), \\\n",
        "1 - gt10_nb['pop'].sum() / nlss_ward_locs.loc[nlss_ward_locs['state'] != 'borno', 'pop'].sum()\n",
        "\n",
        "get_r_ci(dhs_pls_ward_all, 'dhs_rwi', 'nlss_rwi')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BUD2kv-rrr3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Cn8Yzt857Hg1"
      },
      "outputs": [],
      "source": [
        "#@title ML <> NLSS far from DHS scatterplots\n",
        "fig, ax = plt.subplots(1, 6, figsize=(24, 4))\n",
        "cutoffs = [0, 1, 5, 10, 15, 20]\n",
        "\n",
        "plt.title('abc')\n",
        "\n",
        "for i in range(6):\n",
        "    df = nlss_ward_locs[nlss_ward_locs['nearest_dhs_cluster'] >= cutoffs[i]]\n",
        "    sns.scatterplot(x=df['didl_orig_rwi'], y=df['nlss_rwi'], ax=ax[i])\n",
        "    ax[i].set_xlim(nlss_ward_locs['didl_orig_rwi'].min() - 0.1,\n",
        "                   nlss_ward_locs['didl_orig_rwi'].max() + 0.1)\n",
        "    ax[i].set_ylim(nlss_ward_locs['nlss_rwi'].min() - 0.1,\n",
        "                   nlss_ward_locs['nlss_rwi'].max() + 0.1)\n",
        "    ax[i].set_xlabel('ML-based wealth estimate')\n",
        "    ax[i].set_ylabel('NLSS wealth estimate')\n",
        "    if i == 0:\n",
        "        ax[i].set_title('Anywhere outside ward')\n",
        "    else:\n",
        "        ax[i].set_title('%d km' % cutoffs[i])\n",
        "\n",
        "fig.suptitle('Distance to nearest DHS cluster at least X km')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vRbHxKHOrmS6"
      },
      "outputs": [],
      "source": [
        "#@title Correlation between DHS and NLSS wards furthest from DHS clusters\n",
        "\n",
        "dhs_furthest_imputed = dhs_pls_ward_all[['ward', 'dhs_rwi', 'nlss_rwi']]\\\n",
        "    .merge(nlss_ward_locs[['ward', 'nearest_dhs_cluster']])\n",
        "\n",
        "for i in [0, 1, 5, 10, 15, 20]:\n",
        "    df = dhs_furthest_imputed[dhs_furthest_imputed['nearest_dhs_cluster'] >= i]\n",
        "    rho, p, ci = get_r_ci(df, 'dhs_rwi', 'nlss_rwi')\n",
        "    print('nearest DHS ward >=', i,\n",
        "          '| n =', len(df),\n",
        "          '| rho=%.3f (%.3f, %.3f), (p=%.2e)' % (rho, ci[0], ci[1], p))\n",
        "    \n",
        "# nearest DHS ward >= 0 | n = 1552 | rho=0.641 (0.611, 0.670), (p=1.97e-180)\n",
        "# nearest DHS ward >= 1 | n = 1261 | rho=0.580 (0.543, 0.616), (p=1.88e-114)\n",
        "# nearest DHS ward >= 5 | n = 643 | rho=0.411 (0.345, 0.474), (p=1.21e-27)\n",
        "# nearest DHS ward >= 10 | n = 281 | rho=0.233 (0.119, 0.341), (p=7.95e-05)\n",
        "# nearest DHS ward >= 15 | n = 118 | rho=0.318 (0.145, 0.471), (p=4.58e-04)\n",
        "# nearest DHS ward >= 20 | n = 54 | rho=0.200 (-0.071, 0.444), (p=1.46e-01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlGCdto6k4HO"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1EUPNTY_7evp"
      },
      "outputs": [],
      "source": [
        "#@title Get consumption histogram data for R\n",
        "nlss_data.loc[nlss_data['totcons_adj'] < nlss_data['totcons_adj'].quantile(0.999),\n",
        "              ['totcons_adj', 'popw']]\\\n",
        "    .rename({'totcons_adj': 'consumption', 'popw': 'weight'}, axis=1)\\\n",
        "    .to_csv(OUT_DIR + 'consumption_hist.csv', index=False)\n",
        "\n",
        "df = nlss_data[nlss_data['totcons_adj'] < nlss_data['totcons_adj'].quantile(0.999)]\n",
        "df = df[['totcons_adj', 'popw']]\n",
        "ref = []\n",
        "for i in range(len(df)):\n",
        "    row = df.iloc[i]\n",
        "    ref += [row['totcons_adj']] * int(round(row['popw'] / 1000))\n",
        "\n",
        "ref_df = pd.DataFrame({'consumption': ref})\n",
        "ref_df.to_csv(OUT_DIR + 'consumption_hist2.csv', index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1b8J8k4PUDU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqu6Snav9MNk"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "dhxvhNDiZPC0",
        "qQNT7NH_ta_m",
        "CoCxW6LJa7LN",
        "WzIphYDjkRQl",
        "j9ruwd6d2xJ5",
        "frLCrYoC1ab8",
        "FZeSSsFPnURl",
        "PxZ0Z3GE5810",
        "9oD7GhtofyfF",
        "M3a1IjZFgEzg",
        "SdCFfLi1sGuL",
        "C9sElDVTzTuN"
      ],
      "name": "poverty_mapping_code",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}